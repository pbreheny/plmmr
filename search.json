[{"path":"/articles/B-choose_k.html","id":"context-motivation","dir":"Articles","previous_headings":"","what":"Context & motivation","title":"Choosing k -- an eigenproblem","text":"One novel features plmm package way methods address relationships among samples (e.g., patients/participants) data. Unlike mixed models packages like lme4, package based relationships grouping factor. Rather, relationships described matrix cell values capturing degree relationship among pair samples. Let \\(\\mathbf{X}\\) represent \\(n \\times p\\) design matrix data, let \\(\\tilde{\\mathbf{X}}\\) standardized \\(\\mathbf{X}\\) [1]. call \\(n \\times n\\) relationship matrix \\(\\mathbf{K}\\). default, \\(\\mathbf{K}\\) estimated data using data using \\(\\mathbf{K} = \\frac{1}{p} \\tilde{\\mathbf{X}}\\tilde{\\mathbf{X}}^\\top\\) [2]. rotation used plmm_prep() (internal function plmm) requires singular value decomposition (SVD) \\(\\mathbf{K}\\). becomes expensive calculation \\(n\\) large. improve computational time calculation, include optional argument \\(k\\) plmm() function – \\(k\\) parameter invoke truncated SVD. truncated SVD matrix shown optimal rank \\(k\\) approximation matrix (Eckart-Young-Mirsky theorem) [3]. use \\(\\mathbf{}_k\\) represent rank \\(k\\) approximation \\(\\mathbf{K}\\), implement approximation using truncated SVD using RSpectra::svds(). using truncated SVD can improve computational time orders magnitude, approach raises question choose appropriate value \\(k\\). choice one lends ‘rule thumb’ – may \\(k\\) takes approximate SVD \\(\\mathbf{K}\\) well depends (1) makeup specific data (2) user’s definition ‘close’ approximation. help users choose suitable \\(k\\) value use, offer function choose_k(), describe extended example. NOTE: (2024/01/02) latest simulations showing truncating SVD can worsen prediction performance, especially BLUP prediction method. using \\(k < \\text{min}(n,p)\\), make sure keep checking prediction error false discovery rate order assess impact truncated SVD.","code":""},{"path":"/articles/B-choose_k.html","id":"what-this-looks-like-in-practice","dir":"Articles","previous_headings":"","what":"What this looks like in practice","title":"Choosing k -- an eigenproblem","text":"Consider admix genotype data simulated continuous outcome. Suppose want approximate \\(\\mathbf{K}\\). use following: see starting value \\(k\\) 19 – default, choose_k() makes following ‘decisions’: starting value \\(k\\) set tenth \\(n\\) value. controlled start argument. Similarly, default stepsize also one tenth \\(n\\) value. controlled step argument. metric used assess quality approximation Frobenius norm. controlled type argument (see Matrix::norm). \\(\\epsilon\\) value used determine \\(\\delta \\equiv \\frac{||\\mathbf{K} - \\mathbf{}_k||_{\\text{F}}}{||\\mathbf{K}||_{\\text{F}}}\\) satisfactorily small enough automatically set 2. controlled eps argument. user wants smaller \\(\\epsilon\\) start higher value, another option: Notice apparent ‘tweaks’ parameters notable impact choice \\(k\\) – balance parameters art science. can look \\(\\mathbf{}_k\\) matrices produced approximations , comparing true \\(\\mathbf{K}\\) (far right): Now approximations, can use cv.plmm see results:","code":"approx1 <- choose_k(X = admix$X, returnKapprox = T, returnK = T) approx2 <- choose_k(X = admix$X, start = 30, eps = 0.05, returnKapprox = T) par(mfrow=c(1,3)) corrplot(cov2cor(approx1$K_approx),          title = \"Approx. 1\",          mar = c(0,0,2,0),          tl.col = 'grey40',          addgrid.col = NA,           tl.pos = \"n\") corrplot(cov2cor(approx2$K_approx),          title = \"Approx. 2\",          mar = c(0,0,2,0),          tl.col = 'grey40',          addgrid.col = NA,           tl.pos = \"n\") corrplot(cov2cor(approx1$K),          title = \"True K\",          mar = c(0,0,2,0),          tl.col = 'grey40',          addgrid.col = NA,           tl.pos = \"n\") fit1 <- cv.plmm(X = admix$X, y = admix$y, K = approx1$K_svd) fit2 <- cv.plmm(X = admix$X, y = admix$y, K = approx2$K_svd)  par(mfrow=c(1,2)) plot(fit1) plot(fit2) summary(fit1) summary(fit2)"},{"path":"/articles/B-choose_k.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Choosing k -- an eigenproblem","text":"[1] Reisetter, . C., & Breheny, P. (2021). Penalized linear mixed models structured genetic data. Genetic Epidemiology, 45(5), 427-444. [2] CITATION NEEDED standardization [3] Eckart, C., & Young, G. (1936). approximation one matrix another lower rank. Psychometrika, 1(3), 211-218.","code":""},{"path":"/articles/C-explore_options.html","id":"options-for-k-matrix","dir":"Articles","previous_headings":"","what":"Options for K matrix","title":"Exploring different modeling options","text":"One ‘coolest’ aspects plmm approach ability incorporate complex relationships model-fitting process. framework, relational structure data set represented matrix call \\(\\mathbf{K}\\). Imagine matrix quilt symmetric, checkered pattern. complex relational structure data, intricate pattern quilt becomes. relational structure data set include broad loosely related groups, (like ancestry groups), smaller highly correlated groups (like family units).","code":""},{"path":"/articles/C-explore_options.html","id":"structure","dir":"Articles","previous_headings":"Options for K matrix","what":"Structure","title":"Exploring different modeling options","text":"number observations (e.g., number participants) increases, computational time needed calculate entire \\(\\mathbf{K}\\) increases exponentially. reason, plmm() several options approximating \\(\\mathbf{K}\\). First, research contexts may appropriate assume data unrelated observations. cases, plmm() offers argument diag_K = T. use simplest possible ‘quilt pattern’, \\(\\mathbf{K} = \\mathbf{}_n\\) \\(n\\) number observations. can visualize impact two approaches choosing \\(\\mathbf{K}\\): left default option (relatedness_mat()), right option diag_K = T.","code":"# add this plot  fit_admix1 <- plmm(X = admix$X, y = admix$y) fit_admix2 <- plmm(X = admix$X, y = admix$y, diag_K = TRUE) par(mfrow=c(1,2)) plot(fit_admix1);plot(fit_admix2)"},{"path":"/articles/C-explore_options.html","id":"svd-implementation","dir":"Articles","previous_headings":"Options for K matrix","what":"SVD implementation","title":"Exploring different modeling options","text":"computation associated calculating \\(\\mathbf{K}\\) can become quite expensive, code illustrates: can use choose_k() implement truncated singular value decomposition (SVD). shown via RSpectra::svds().","code":"#TODO: add these plots  K_dim <- c(100, 1000, 1500, 2000, 3000, 4000) true_times <- approx_times <- rep(NA, length(K_dim)) pb <- txtProgressBar(min = 1, max = length(K_dim), initial = 1, style = 3) for (i in 1:length(K_dim)){   n <- K_dim[i]   true_times[i] <- svd(relatedness_mat(X = matrix(rnorm(n, 10), n, 10))) |>      system.time()    approx_times[i] <- RSpectra::svds(relatedness_mat(X = matrix(rnorm(n, 10), n, 10)),                                     k = floor(0.1*n)) |> system.time()    setTxtProgressBar(pb, i) }  K_dat <- data.frame(true_times, approx_times, K_dim) ggplot(K_dat,        aes(x = K_dim)) +    geom_line(aes(y = true_times)) +    geom_line(aes(y = approx_times), linetype = 'dashed') +    labs(x = \"nrow(X): the dimension of the K matrix\",        y = \"SVD time in seconds\")"},{"path":"/articles/C-explore_options.html","id":"options-for-type-in-prediction","dir":"Articles","previous_headings":"","what":"Options for ‘type’ in prediction","title":"Exploring different modeling options","text":"PLMMs (well contexts), goal model building predict outcomes new data \\(X_2\\) based data outcomes \\(X_1, y_1\\). package offers two options prediction, ‘lp’ ‘blup’, user may specify via type argument cv.plmm() related functions. LP acronym “Linear Predictor” BLUP acronym Best Linear Unbiased Predictor. linear predictor (LP) \\(X_2 \\hat \\beta(\\lambda)\\), whereas Best Linear Unbiased Predictor (BLUP) \\(X_2 \\hat \\beta(\\lambda) + V_{21} V_{11}^{\\frac{-1}{2}}(\\tilde y_1 - \\tilde X_1 \\hat \\beta(\\lambda))\\), : \\(V_{n \\times n} \\equiv \\eta \\mathbf{K} + (1 - \\eta)\\mathbf{}_n\\) matrix describing correlation among \\(n\\) observations \\(X\\). matrix re-expressed \\(V_{n \\times n} \\equiv \\eta*(U \\text{diag}(S)U^\\top) + (1 - \\eta)I_n\\) via singular value decomposition. \\(\\tilde X_1\\) \\(\\tilde y_1\\) standardized rotated design matrix outcomes. (bullet work progress… need think .) symbol \\(\\eta\\) represents percentage \\(\\text{Var}(y)\\) attributable additive effects features (context genetics, narrow-sense heritability). \\(\\eta\\) also captures signal--noise ratio (SNR) data-generating mechanism (model). estimate \\(\\eta\\) \\(\\hat \\eta = \\text{argmin} \\ell (U, S, y)\\), value minimizes log-likelihood function (see estimate_eta() documentation details). Note BLUP includes LP first term, adds second term representing predicted random effect. means BLUP accounts covariance structure data, whereas LP incorporate structure. can compare results options :","code":"set.seed(615) cv_admix1 <- cv.plmm(X = admix$X, y = admix$y) set.seed(615) cv_admix1_blup <- cv.plmm(X = admix$X, y = admix$y, type = \"blup\")  par(mfrow=c(1,2)); plot(cv_admix1); plot(cv_admix1_blup) summary(cv_admix1);summary(cv_admix1_blup)"},{"path":"/articles/C-explore_options.html","id":"options-for-looking-at-bias-and-variance","dir":"Articles","previous_headings":"","what":"Options for looking at bias and variance","title":"Exploring different modeling options","text":"may interest examine bias variance result cross-validated model fitting. cv.plmm() option returnBiasDetails; set TRUE, make returned object include bias (vector) loss (matrix). Moreover, plmm model fit, function v_hat construct approximated matrix \\(\\mathbf{\\hat V} \\equiv \\eta \\mathbf{K} + (1 - \\eta)\\mathbf{}_n\\).","code":""},{"path":"/articles/D-deconfounding.html","id":"context","dir":"Articles","previous_headings":"","what":"Context","title":"Deconfounding","text":"want explore different types confounding impact PLMMs — questions mind include: PLMM perform well? perform poorly? PLMM compare PCA different data contexts? PLMM uses PCs fixed effects – sense, ‘hybrid’ approach – way approach deconfounding data complex structure?","code":""},{"path":"/articles/D-deconfounding.html","id":"starting-with-some-test-data","dir":"Articles","previous_headings":"","what":"Starting with some test data","title":"Deconfounding","text":"Let’s compare three lasso models: glmnet, plmm linear predictor (default), plmm BLUP option.","code":"library(glmnet) gb <- function(n=100, p=256, s=4, gamma=6, beta=2, B=20) {   mu <- matrix(rnorm(B*p), B, p)   z <- rep(1:B, each=n/B)   X <- matrix(rnorm(n*p), n, p) + mu[z,] |>     ncvreg::std()   b <- rep(c(beta, 0), c(s, p-s))   g <- seq(-gamma, gamma, length=B)   y <- X %*% b + g[z]   Z <- model.matrix(~0+factor(z))   list(y=y, X=X, beta=b, Z=Z, gamma=g, mu=mu, id=z) } l <- gb() cvg <- cv.glmnet(l$X, l$y) cvp <- cv.plmm(l$X, l$y, penalty='lasso') cvp_blup <- cv.plmm(l$X, l$y, penalty='lasso',                     type = 'blup',                     returnBiasDetails = TRUE)  # look at K -- note that this data scenario has a 'finer' population structure library(corrplot) corrplot(relatedness_mat(l$X), is.corr = F, tl.pos = \"n\")"},{"path":"/articles/D-deconfounding.html","id":"mspe","dir":"Articles","previous_headings":"Starting with some test data","what":"MSPE","title":"Deconfounding","text":"mean squared prediction error glmnet plmm, adding blup option makes improvement:","code":"min(cvg$cvm) min(cvp$cve) min(cvp_blup$cve)"},{"path":"/articles/D-deconfounding.html","id":"mse","dir":"Articles","previous_headings":"Starting with some test data","what":"MSE","title":"Deconfounding","text":"mean squared error, see \\(\\hat \\beta\\) better plmm, better still plmm + BLUP.","code":"crossprod(l$beta - coef(cvg)[-1]) |> drop() crossprod(l$beta - coef(cvp)[-1]) |> drop() crossprod(l$beta - coef(cvp_blup)[-1]) |> drop()"},{"path":"/articles/E-mfdr.html","id":"background-and-motivation","dir":"Articles","previous_headings":"","what":"Background and motivation","title":"Inference with marginal false discovery rates","text":"cross validation (cv.plmm()) serves method assessing model’s ability predict outcomes new data, cross validation geared towards making inferences \\(\\hat \\beta\\) values (coefficients) estimated model. use PLMM, often want answer questions like: “reliable selections made model chose?” “accurate estimated \\(\\hat \\beta\\) values?” One way address important questions marginal false discovery rates (mFdr). mFdr framework, can estimate mFdr value value \\(\\lambda\\) penalized regression model. gives another way compare different models. Instead just comparing cross-validation error, can also compare number probable false discoveries features chosen model. interested statistical theory behind method, recommend advisor’s free online lecture notes. article, use mfdr() function illustrate marginal false discovery rates can used compare models fit plmm() cv.plmm().","code":""},{"path":[]},{"path":"/articles/E-mfdr.html","id":"admix-data","dir":"Articles","previous_headings":"Examples","what":"Admix data","title":"Inference with marginal false discovery rates","text":"Let’s begin simple example using semi-simulated admix data. compare 3 models: fit 1: model singular values fixed effects. fit 2: model \\(k\\) singular values fixed effects. fit 3: model \\(k\\) singular values top 4 principal components fixed effects. fit, use cross validation select value \\(\\lambda\\) best prediction.","code":""},{"path":"/articles/E-mfdr.html","id":"fit-1","dir":"Articles","previous_headings":"Examples > Admix data","what":"fit 1","title":"Inference with marginal false discovery rates","text":"","code":"# construct a cross-validated lasso model  cv_fit1 <- cv.plmm(X = admix$X,               y = admix$y,               penalty = \"lasso\",               # remember to set a seed for reproducibility                seed = 26)  # look at results  fit1 <- cv_fit1$fit summary(cv_fit1) # Calculate mFdr # head(mfdr(fit1)) mfdr1 <- mfdr(fit1)[cv_fit1$min,]"},{"path":"/articles/E-mfdr.html","id":"fit-2","dir":"Articles","previous_headings":"Examples > Admix data","what":"fit 2","title":"Inference with marginal false discovery rates","text":"","code":"# choose k  admix$k <- choose_k(X = admix$X, returnKapprox = T)  # construct the model  cv_fit2 <- cv.plmm(X = admix$X,                    y = admix$y,                    K = admix$k$K_svd,                    seed = 26)  # look at results  fit2 <- cv_fit2$fit summary(cv_fit2) # Calculate mFdr # head(mfdr(fit2)) mfdr2 <- mfdr(fit2)[cv_fit2$min,]"},{"path":"/articles/E-mfdr.html","id":"fit-3","dir":"Articles","previous_headings":"Examples > Admix data","what":"fit 3","title":"Inference with marginal false discovery rates","text":"principal components calculated, can now fit third model:","code":"# standardize design matrix and remove constant features  std_X <- ncvreg::std(admix$X) # calculate PCs from *standardized* data pca <- prcomp(std_X, center = F, scale = F) # plot the top 10 PCs in a scree plot  plot(x = 1:10,      y = 100 * proportions(pca$sdev[1:10]^2),      type = 'b',      ylab = 'Proportion of variance explained',      xlab = 'PC',      main = 'Scree Plot') # first 4 PCs explain most of the variance, so we will use these as fixed effects; this makes sense given the ancestry of the participants  pca_dat <- data.frame(race = admix$race, PC1 = pca$x[,1], PC2 = pca$x[, 2]) pca_plot <- ggplot(pca_dat, aes(x = PC1, y = PC2, col = as.factor(race))) +   geom_point() +   coord_fixed() plot(pca_plot)  PCs <- pca$x # look at the PCs  # pca$x[1:5, 1:4] # incorporate 4 PCs as fixed effects  admix$X_plus_PCs <- cbind(PCs[,1:4], admix$X) # construct the model  cv_fit3 <- cv.plmm(X = admix$X_plus_PCs,                    y = admix$y,                    K = admix$k$K_svd,                    # make sure not to penalize fixed effects - we want to keep                     #  these in the model!                    penalty.factor = c(rep(0, 4), rep(1, ncol(admix$X))),                    seed = 26)  # look at results  fit3 <- cv_fit3$fit summary(cv_fit3) # Calculate mFdr # head(mfdr(fit3)) mfdr3 <- mfdr(fit3)[cv_fit3$min,]"},{"path":"/articles/E-mfdr.html","id":"comparisons","dir":"Articles","previous_headings":"Examples","what":"Comparisons","title":"Inference with marginal false discovery rates","text":"Let’s compare results three models using admix data: observations based plots output : * simulated outcome, 2 \\(\\beta\\) values truly nonzero (.e., 2 SNPs (SNPs 17 85) actually associated outcome - see data-raw/admix.R details). mind, results leave lot desired… still thinking /wondering explain phenomena. Marginal false discovery rates also give us another way select \\(\\lambda\\): instead choosing \\(\\lambda\\) value minimizes cross validation error, choose value limits mFdr certain level. can examine approach models fit :","code":"# columns are ordered by models 1-3 # rows are CV plots & coefficient path plots par(mfrow = c(2,3)) plot(cv_fit1); plot(cv_fit2); plot(cv_fit3) plot(fit1); plot(fit2); plot(fit3)  admix_comparison <- as.data.table(rbind(mfdr1, mfdr2, mfdr3)) admix_comparison[, model := paste0(\"Model \", 1:3)] admix_comparison[, .(model, EF, S, mFDR)] |>   kable(digits=2, caption = \"Comparing 3 models at their respective lambda.min values\") # let's look at lambda where mFDR is smallest, instead of mFDR where lambda = lambda.min (minimum CVE)  # fit 1  (mfdr1[which.min(mfdr1$mFDR),])  # fit 2  (mfdr2[which.min(mfdr2$mFDR),])  # fit 3  (mfdr3[which.min(mfdr3$mFDR),])"},{"path":"/articles/E-mfdr.html","id":"penncath-data-high-dimensional","dir":"Articles","previous_headings":"Examples","what":"Penncath data (high dimensional)","title":"Inference with marginal false discovery rates","text":"Let’s similar model comparison, time using penncath_lite data. TODO: come back finish adding output later; data represent 1,401 individuals 4,367 SNPs GWAS study. sake example, let’s use hdl (high-density lipoprotein cholesterol) outcome.","code":"# preprocess PLINK files penncath_lite <- process_plink(   data_dir = plink_example(parent = TRUE),   prefix = \"penncath_lite\",   gz = TRUE, # NB: PLINK data that ships with package comes gzipped   impute = TRUE, # mode imputation is default    outfile = \"process_penncath\") # read in the data to global environment  # NB: this assumes article A ('Plink Files') has already been run.  # read in the data to global environment pen <- get_data(path = paste0(plink_example(parent = TRUE), \"/penncath_lite\"))  str(pen) # Three objects here # NB: the 'quiet' option in process_plink()  will silence the printed messages pen_cl <- read.csv(plink_example(path = 'penncath_clinical.csv'))  # for the sake of illustration, I use a simple mean imputation for the outcome  pen$y <- ifelse(is.na(pen_cl$hdl),                 mean(pen_cl$hdl, na.rm = T), pen_cl$hdl)"},{"path":"/articles/E-mfdr.html","id":"fit-1-1","dir":"Articles","previous_headings":"Examples > Penncath data (high dimensional)","what":"fit 1","title":"Inference with marginal false discovery rates","text":"Hmm – found mFdr 1 fit 1, great application standpoint. due true lack association SNPs HDL outcome, may also estimation issue. Remember, articles work progress… next model, use MCP instead lasso.","code":"# construct a cross-validated lasso model  cv_pen1 <- cv.plmm(X = pen$X,               y = pen$y,               penalty = \"lasso\",               # remember to set a seed for reproducibility                seed = 26)  # look at results  pen1 <- cv_pen1$fit summary(cv_pen1) # Calculate mFdr # head(mfdr(pen1)) (pen_mfdr1 <- mfdr(pen1)[cv_pen1$min,])"},{"path":"/articles/E-mfdr.html","id":"fit-2-1","dir":"Articles","previous_headings":"Examples > Penncath data (high dimensional)","what":"fit 2","title":"Inference with marginal false discovery rates","text":"","code":"pen$k <- choose_k(pen$X, returnKapprox = T)  cv_pen2 <- cv.plmm(X = pen$X,         y = pen$y,         K = pen$k$K_svd,         seed = 26)  pen2 <- cv_pen2$fit summary(cv_pen2) (pen_mfdr2 <- mfdr(pen2)[cv_pen2$min,])"},{"path":"/articles/E-mfdr.html","id":"fit-3-1","dir":"Articles","previous_headings":"Examples > Penncath data (high dimensional)","what":"fit 3","title":"Inference with marginal false discovery rates","text":"Finally, model ‘penncath’ data one time using sex first principal components","code":"pen$std_X <- ncvreg::std(pen$X) pen_pca <- prcomp(pen$std_X, center = F, scale. = F)  # scree plot  plot(x = 1:10,      y = 100 * proportions(pen_pca$sdev[1:10]^2),      type = 'b',      ylab = 'Proportion of variance explained',      xlab = 'PC',      main = 'Scree Plot')  # will use 10 PCs as fixed effects  pen_PCs <- pen_pca$x pen$X_plus_fixed_eff <- cbind(pen$fam[,c(\"sex\")], pen_PCs[,1:10], pen$X)  cv_pen3 <- cv.plmm(X = pen$X_plus_fixed_eff,                    y = pen$y,                     # start at 1200 based on result from the previous fit                    k = 1200,                    penalty.factor = c(rep(0,12), rep(1,ncol(pen$X))),                    seed = 26)  pen3 <- cv_pen3$fit summary(cv_pen3)  (pen_mfdr3 <- mfdr(pen3)[cv_pen3$min,])"},{"path":"/articles/E-mfdr.html","id":"comparisons-1","dir":"Articles","previous_headings":"Examples","what":"Comparisons","title":"Inference with marginal false discovery rates","text":"Comparing three fits ‘penncath’ data, can observe following: can also look mFDR changes among three models:","code":"par(mfrow = c(2,3)) plot(cv_pen1); plot(cv_pen2); plot(cv_pen3) plot(pen1); plot(pen2); plot(pen3) pen_comparison <- rbind(pen_mfdr1, pen_mfdr2, pen_mfdr3) |>   as.data.table(keep.rownames='lambda') pen_comparison[, model := paste0(\"Model \", 1:3)] pen_comparison[, .(model, EF, S, mFDR)] |>   kable(digits=3) compare_mfdr <- rbind(mfdr(pen1), mfdr(pen2), mfdr(pen3)) |>   as.data.table(keep.rownames='lambda') compare_mfdr[, model := c(rep(\"lasso\", 100),                           rep(\"MCP + trunc. SVD\", 100),                           rep('MCP + trunc. SVD + fixed eff', 100))] compare_mfdr[, log_lam := log(as.numeric(lambda))] ggplot(compare_mfdr, aes(x = log_lam, y = mFDR)) +    geom_line(aes(colour = model)) +    labs(x = expression(log(lambda)))"},{"path":"/articles/E-mfdr.html","id":"local-false-discovery-rates","dir":"Articles","previous_headings":"","what":"Local false discovery rates","title":"Inference with marginal false discovery rates","text":"beginning vignette, examined important questions inference. Let’s consider additional question often arises practice: “Can assess features (e.g., SNPs, predictors) likely false discoveries, features likely truly connected outcome care ?”. question individual features, rather model. One way address question local marginal false discovery rates (lmfdr). local mFdr framework takes mFdr feature level, mFdr value estimated \\(\\hat \\beta\\) penalized regression model. Using mFdr values, can rank selected features scale 0 1. feature mFdr value closer zero high probability associated outcome interest, whereas feature mFdr value closer 1 probably false discovery. Example come … future, want adapt ncvreg:::local_mfdr() work PLMMs.","code":""},{"path":"/articles/E-mfdr.html","id":"references-acknowledgements","dir":"Articles","previous_headings":"","what":"References & acknowledgements","title":"Inference with marginal false discovery rates","text":"mfdr() function incorporated plmm package based Ryan Miller’s joint work Patrick Breheny ncvreg::mfdr() package. read work, see Miller & Breheny (2023) Stats Medicine. Penncath data: data describe coronary artery disease outcomes PennCath study). data set subset much larger data set (original data 800K SNPs); chose create ‘lite’ version vignette purposes. information data set, refer original publication.","code":""},{"path":"/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting started with plmm","text":"plmmr (stands Penalized Linear Mixed Models R) R package created purpose fitting penalized regression models high dimensional data, particularly observations correlated. kind data arises often context genetics (e.g. GWAS dealing population structure/family structure), motivation examples presented . time, package designed linear regression – , considering continuous (numeric) outcomes. many applications high dimensional data, objective statistical models identify signals - example, many GWAS interested identifying set variants show evidence association outcome. Practitioners situations often interested identifying biological pathways estimating odds ratios individual variants. applications, treating binary categorical outcomes numeric values possibility. future, like extend package handle logistic regression (handle dichotomous outcomes). Since focused penalized regression package, plmmr offers 3 choices penalty: minimax concave (MCP), smoothly clipped absolute deviation (SCAD), least absolute shrinkage selection operator (LASSO). 1 Much work package built concepts/techniques provided ncvreg package Patrick Breheny. filebacked computation relies bigsnpr package Florian Privé biglasso package Yaohui Zeng & Patrick Breheny. plmmr currently includes two example data sets: admix small data set (197 observations, 100 SNPs) describes individuals different ancestry groups. outcome admix simulated include population structure effects (.e. race/ethnicity impact SNP associations). data set available .rda object data/ folder. penncath_lite (data coronary artery disease PennCath study) mid-sized, high dimensional data set (1401 observations, 4217 SNPs) several health outcomes well age sex information. data set subset much larger data set (original data 800K SNPs). information data set, refer original publication. overview, provide demo main functions plmmr using admix data. Checkout ‘Working PLINK files’ vignette see demo processing penncath_lite data original PLINK file formats.","code":""},{"path":"/articles/getting-started.html","id":"basic-model-fitting","dir":"Articles","previous_headings":"","what":"Basic model fitting","title":"Getting started with plmm","text":"admix data already formatted elements \\(X\\) \\(y\\), can jump right call plmmr::plmm() (main function): returned beta_vals item matrix whose rows \\(\\hat\\beta\\) coefficients whose columns represent values penalization parameter \\(\\lambda\\). default, plmm fits 100 values \\(\\lambda\\) (see setup_lambda function details). Note values \\(\\lambda\\), SNP 8 \\(\\hat \\beta = 0\\). SNP 8 constant feature, feature (column) whose values vary among members population. can summarize fit nth \\(\\lambda\\) value: can also plot path fit see model coefficients vary \\(\\lambda\\): Plot path model fit Suppose also know ancestry groups person admix data self-identified. probably want include model unpenalized covariate (.e., want ‘ancestry’ always model). look:","code":"admix_fit <- plmm(X = admix$X, y = admix$y) summary(admix_fit, lambda = admix_fit$lambda[95]) #> MCP-penalized regression model with n=197, p=101 at lambda=0.00061 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  98  #> ------------------------------------------------- admix_fit$beta_vals[1:10, 97:100] |>    knitr::kable(digits = 3,                format = \"html\") # for n = 25  summary(admix_fit, lambda = admix_fit$lambda[25]) #> MCP-penalized regression model with n=197, p=101 at lambda=0.08018 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  43  #> ------------------------------------------------- plot(admix_fit) admix_fit2 <- plmm(X = cbind(admix$race, admix$X), y = admix$y,                    penalty = \"lasso\",                    # make the penalty factor 0 to keep the corresponding covariate unpenalized                    penalty.factor = c(0, rep(1, ncol(admix$X))))  summary(admix_fit2, idx = 95) #> lasso-penalized regression model with n=197, p=102 at lambda=0.00076 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  98  #> ------------------------------------------------- plot(admix_fit2)"},{"path":"/articles/getting-started.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross validation","title":"Getting started with plmm","text":"select \\(\\lambda\\) value, often use cross validation. example using cv.plmm select \\(\\lambda\\) minimizes cross-validation error: can also plot cross-validation error (CVE) versus \\(\\lambda\\) (log scale): Plot CVE","code":"admix_cv <- cv.plmm(X = cbind(admix$race, admix$X), y = admix$y,                     penalty = \"lasso\", penalty.factor = c(0, rep(1, ncol(admix$X)))) admix_cv_s <- summary(admix_cv, lambda = \"min\") print(admix_cv_s) #> lasso-penalized model with n=197 and p=101 #> At minimum cross-validation error (lambda=0.1888): #> ------------------------------------------------- #>   Nonzero coefficients: 3 #>   Cross-validation error (deviance): 1.18 #>   Scale estimate (sigma): 1.088 plot(admix_cv)"},{"path":"/articles/getting-started.html","id":"predicted-values","dir":"Articles","previous_headings":"","what":"Predicted values","title":"Getting started with plmm","text":"example predict() methods PLMMs: can compare predictions predictions get intercept-model using mean squared prediction error (MSPE) – lower better: see model better predictions null","code":"# make predictions for select lambda value(s) y_hat <- predict(object = admix_fit,                        newX = admix$X,                        type = \"blup\",                        X = admix$X,                        y = admix$y,                        lambda = admix_cv$lambda.min) # intercept-only (or 'null') model crossprod(admix$y - mean(admix$y))/length(admix$y) #>          [,1] #> [1,] 5.928528  # our model crossprod(admix$y - y_hat)/length(admix$y) #>          [,1] #> [1,] 1.120102"},{"path":"/articles/notation.html","id":"math-notation","dir":"Articles","previous_headings":"","what":"Math notation","title":"Notes on notation","text":"concepts need denote, order usage derivations. blocked sections corresponding steps model fitting process.","code":""},{"path":"/articles/notation.html","id":"statistical-model-the-overall-framework","dir":"Articles","previous_headings":"Math notation","what":"Statistical model (the overall framework)","title":"Notes on notation","text":"overall model can written \\[ \\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{\\gamma} + \\boldsymbol{\\epsilon} \\] equivalently \\[ \\mathbf{y} = \\dot{\\mathbf{X}}\\dot{\\boldsymbol{\\beta}} + \\mathbf{u} + \\boldsymbol{\\epsilon} \\] : \\(\\mathbf{X}\\) \\(\\mathbf{y}\\) \\(n \\times p\\) design matrix data \\(n \\times 1\\) vector outcomes, respectively. , \\(n\\) number observations (e.g., number patients, number samples, etc.) \\(p\\) number features (e.g., number SNPs, number variables, number covariates, etc.). \\(\\dot{\\mathbf{X}}\\) column-standardized \\(\\mathbf{X}\\), \\(p\\) columns mean 0 standard deviation 1. Note: \\(\\dot{\\mathbf{X}}\\) excludes singular features (columns constants) original \\(\\mathbf{X}\\). \\(\\dot{\\boldsymbol{\\beta}}\\) represents coefficients standardized scale. \\(\\mathbf{Z}\\) \\(n \\times b\\) matrix indicators corresponding grouping structure, \\(\\boldsymbol{\\gamma}\\) vector values describing grouping associated \\(\\mathbf{y}\\). real data, values typically unknown. \\(\\boldsymbol{\\epsilon}\\) \\(n \\times 1\\) vector noise. define realized (empirical) relatedness matrix \\(\\mathbf{K} \\equiv \\frac{1}{p}\\dot{\\mathbf{X}}\\dot{\\mathbf{X}}^\\top\\) model assumes: \\(\\boldsymbol{\\epsilon} \\perp \\mathbf{u}\\) \\(\\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_{\\epsilon}\\mathbf{})\\) \\(\\mathbf{u} \\sim N(0, \\sigma^2_{s}\\mathbf{K})\\) assumptions, may write \\(\\mathbf{y} \\sim N(\\dot{\\mathbf{X}}\\dot{\\boldsymbol{\\beta}}, \\boldsymbol{\\Sigma})\\) Indices: \\(\\1,..., n\\) indexes observations \\(j \\1,..., p\\) indexes features \\(h \\1,..., b\\) indexes batches (e.g., different family groups, different data collection sites, etc.)","code":""},{"path":"/articles/notation.html","id":"decomposition-and-rotation-prep-and-first-part-of-fit","dir":"Articles","previous_headings":"Math notation","what":"Decomposition and rotation (prep and first part of fit)","title":"Notes on notation","text":"Beginning singular value decomposition, \\(\\mathbf{U}\\) \\(\\mathbf{d}\\) right singular vectors singular values \\(\\dot{\\mathbf{X}}\\), one obtain singular value decomposition (SVD), .e. \\(\\text{svd}(\\mathbf{X)} \\equiv \\mathbf{U}\\mathbf{D}\\mathbf{V}^\\top\\). elements \\(\\mathbf{d}\\) diagonal values \\(\\mathbf{D}\\). Note, random effect \\(\\mathbf{u}\\) distinct columns matrix \\(\\mathbf{U}\\). \\(k\\) represents number nonzero eigenvalues represented \\(\\mathbf{U}\\) \\(\\mathbf{d}\\), \\(k \\leq \\text{min}(n,p)\\). \\(\\mathbf{S} \\equiv \\frac{1}{p}\\mathbf{D}^2\\) \\(k \\times k\\) diagonal matrix whose diagonal values \\(\\frac{d_k^2}{p}\\). , \\(\\mathbf{K} \\equiv \\frac{1}{p}\\dot{\\mathbf{X}}\\dot{\\mathbf{X}}^{\\top}\\)often referred literature realized relatedness matrix (RRM) genomic relatedness matrix (GRM). \\(\\mathbf{K}\\) dimension \\(n \\times n\\). Note \\(\\mathbf{K}\\) can obtained SVD \\(\\dot{\\mathbf{X}}\\), .e., \\(\\mathbf{U}\\mathbf{S}\\mathbf{U}^{\\top}\\), \\(\\mathbf{S}\\) diagonal matrix whose diagonal values \\(\\frac{d_k^2}{p}\\). \\(\\eta\\) ratio \\(\\frac{\\sigma^2_s}{\\sigma^2_e + \\sigma^2_s}\\). estimate \\(\\hat{\\eta}\\) null model (details come). \\(\\mathbf{\\Sigma}\\) variance outcome, \\(\\mathbb{V}({\\mathbf{y}}) = \\eta \\mathbf{K} + (1 - \\eta)\\mathbf{}_n\\). \\(\\mathbf{w}\\) vector weights defined \\((\\eta\\mathbf{\\mathbf{s}} + (1-\\eta))^{-1/2}\\). values \\(\\mathbf{w}\\) nonzero values diagonal matrix \\(\\mathbf{W} \\equiv (\\eta\\mathbf{S} + (1 - \\eta)\\mathbf{})^{-1/2}\\). matrix used rotating ( preconditioning) data \\(\\mathbf{\\Sigma}^{-1/2} \\equiv \\mathbf{W}\\mathbf{U}^\\top\\). \\(\\tilde{\\dot{\\mathbf{X}}} \\equiv \\mathbf{W}\\mathbf{U}^\\top\\dot{\\mathbf{X}}\\) rotated data, data transformed scale. \\(\\tilde{\\mathbf{y}} \\equiv \\mathbf{\\Sigma}^{-1/2}\\mathbf{y}\\) outcome rotated scale. \\(\\ddot{\\tilde{\\mathbf{X}}}\\) standardized rotated data. Note: standardization involves scaling, centering. post-rotation standardization impacts estimated coefficients well; define \\({\\ddot{\\boldsymbol{\\beta}}}\\) estimated coefficients scale.","code":""},{"path":"/articles/notation.html","id":"model-fitting-with-penalization","dir":"Articles","previous_headings":"Math notation","what":"Model fitting with penalization","title":"Notes on notation","text":"fit \\(\\tilde{\\mathbf{y}} \\sim \\ddot{\\tilde{\\mathbf{X}}}\\) using penalized linear mixed model, obtain \\(\\hat{\\ddot{\\boldsymbol{\\beta}}}\\) estimated coefficients. penalty parameter values (e.g., values lasso tuning parameter) indexed \\(\\lambda_l \\1,..., t\\).","code":""},{"path":"/articles/notation.html","id":"rescaling-results-format","dir":"Articles","previous_headings":"Math notation","what":"Rescaling results (format)","title":"Notes on notation","text":"obtain estimated coefficients original scale, values estimated model must unscaled (‘untransformed’) twice: adjust post-rotation standardization, adjust pre-rotation standardization. process written \\(\\hat{\\ddot{\\boldsymbol{\\beta}}} \\rightarrow \\hat{\\dot{\\boldsymbol{\\beta}}} \\rightarrow \\hat{\\boldsymbol{\\beta}}\\).","code":""},{"path":"/articles/notation.html","id":"object-names-in-source-code","dir":"Articles","previous_headings":"","what":"Object names in source code","title":"Notes on notation","text":"code, denote objects way: \\(\\mathbf{X}\\) \\(\\mathbf{y}\\) X y \\(\\dot{\\mathbf{X}}\\) std_X \\(\\tilde{\\dot{\\mathbf{X}}}\\) rot_X \\(\\ddot{\\tilde{\\mathbf{X}}}\\) stdrot_X \\(\\dot{\\mathbf{X}}\\dot{\\boldsymbol{\\beta}}\\) Xb","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Anna C. Reisetter. Author. Patrick J. Breheny. Author. Tabitha K. Peter. Author, maintainer. Yujing Lu. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reisetter , Breheny P, Peter T, Lu Y (2024). plmmr: Fit nonconvex-penalized linear mixed models account presence unobserved confounding effects. R package version 2.2.1.","code":"@Manual{,   title = {plmmr: Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects},   author = {Anna C. Reisetter and Patrick J. Breheny and Tabitha K. Peter and Yujing Lu},   year = {2024},   note = {R package version 2.2.1}, }"},{"path":"/index.html","id":"welcome","dir":"","previous_headings":"","what":"Welcome","title":"Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects","text":"plmmr package contains functions fit penalized linear mixed models correct unobserved confounding effects. Documentation package progress.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects","text":"install latest version package: description motivation functions package (along examples) refer second module GWAS data tutorial","code":"devtools::install_github(\"pbreheny/plmmr\")"},{"path":"/index.html","id":"latest-changes","dir":"","previous_headings":"","what":"Latest changes","title":"Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects","text":"newest features plmmr : - version 2.2.0: parameter η longer estimated fold cross-validation version 2.1.0: new function mfdr() inference model coefficients. version 2.0.3: xgboost method now available process_plink(). Check documentation details. option regarded ‘beta-testing’ mode.","code":""},{"path":"/index.html","id":"note-on-branches","dir":"","previous_headings":"","what":"Note on branches","title":"Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects","text":"branches repo organized following way: master main branch latest updates prep_for_cran development branch bug fixes/polishing things preparation first CRAN submission (coming soon!) estimate_eta development branch worked alternative approach estimating η. ’re keeping around reference writing. fbm development branch working extend current methods analyze data design matrix stored file-backed object (Filebacked Big Matrix, FBM). See package bigstatsr info objects. sign_flip development branch toying handle issues caused +/- signs flipped part truncated SVD. refine_workflow archived branch explored changing workflow make cross validation efficient. change involved moving rotation step plmm_prep(), instead step part model fitting plmm_fit(). found change compatible cross validation, reasons currently writing part paper. paper done, delete branch.","code":""},{"path":"/reference/admix.html","id":null,"dir":"Reference","previous_headings":"","what":"Admix: Semi-simulated SNP data — admix","title":"Admix: Semi-simulated SNP data — admix","text":"dataset containing 100 SNPs, demographic variable representing race, simulated outcome","code":""},{"path":"/reference/admix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Admix: Semi-simulated SNP data — admix","text":"","code":"admix"},{"path":"/reference/admix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Admix: Semi-simulated SNP data — admix","text":"list 3 components X SNP matrix (197 observations 100 SNPs) y vector simulated (continuous) outcomes race vector racial group categorization: # 0 = African, 1 = African American, 2 = European, 3 = Japanese","code":""},{"path":"/reference/admix.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Admix: Semi-simulated SNP data — admix","text":"https://hastie.su.domains/CASI/","code":""},{"path":"/reference/choose_k.html","id":null,"dir":"Reference","previous_headings":"","what":"a function to choose k, the number of eigenvalues to use in truncated SVD — choose_k","title":"a function to choose k, the number of eigenvalues to use in truncated SVD — choose_k","text":"function choose k, number eigenvalues use truncated SVD","code":""},{"path":"/reference/choose_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a function to choose k, the number of eigenvalues to use in truncated SVD — choose_k","text":"","code":"choose_k(   X,   start = NULL,   step = NULL,   eps = 0.1,   trace = TRUE,   type = \"F\",   returnKapprox = TRUE,   returnK = FALSE )"},{"path":"/reference/choose_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a function to choose k, the number of eigenvalues to use in truncated SVD — choose_k","text":"X can either: fully-imputed design matrix, string specifying path .rds object created process_plink start starting number eigenvalues. Defaults floor(nrow(X)/10) step size (respect number observations) increments increase choosing k. Defaults floor(nrow(X)/10). eps percentage indicating largest permissible approximation error true approximate relatedness matrices. Defaults 0.1 (10% error). trace Logical: progress bars messages printed console? Defaults TRUE. type type norm use determining distance true approximate K. Defaults 'F', Frobenious norm. See Matrix::norm() details. returnKapprox Logical: addition list SVD components approximated K, approximation returned matrix? Defaults TRUE. returnK Logical: true K (relatedness_mat(X)) returned? Defaults FALSE.","code":""},{"path":"/reference/choose_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"a function to choose k, the number of eigenvalues to use in truncated SVD — choose_k","text":"list least 3 items: eigs_K: list SVD components (s U) approximated relatedness matrix K can passed plmm() k, chosen number eigenvalues delt, distance true approximated K matrices chosen k k_vals, vector k values evaluated inv_delt_vals, vector 1-delta k values evaluated. See delta() details. optional: returnKapprox, K_approx returned optional: returnK, K returned","code":""},{"path":"/reference/choose_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"a function to choose k, the number of eigenvalues to use in truncated SVD — choose_k","text":"","code":"if (FALSE) { res <- choose_k(X = admix$X, start = 10, step = 10, trace = TRUE) plot(x = res$k_vals, y = res$inv_delt_vals, type = \"l\") }"},{"path":"/reference/coef.cv.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Coef method for ","title":"Coef method for ","text":"Coef method \"cv.plmm\" class","code":""},{"path":"/reference/coef.cv.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coef method for ","text":"","code":"# S3 method for cv.plmm coef(object, lambda, which = object$min, ...)"},{"path":"/reference/coef.cv.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coef method for ","text":"object object class \"cv.plmm.\" lambda numeric vector lambda values. Vector lambda indices coefficients return. Defaults lambda index minimum CVE. ... Additional arguments (used).","code":""},{"path":"/reference/coef.cv.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coef method for ","text":"","code":"if (FALSE) { cv_fit <- cv.plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X)) head(coef.cv.plmm(cv_fit)) }"},{"path":"/reference/coef.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Coef method for ","title":"Coef method for ","text":"Coef method \"plmm\" class","code":""},{"path":"/reference/coef.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coef method for ","text":"","code":"# S3 method for plmm coef(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)"},{"path":"/reference/coef.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coef method for ","text":"object object class \"plmm.\" lambda numeric vector lambda values. Vector lambda indices coefficients return. drop Logical. ... Additional arguments.","code":""},{"path":"/reference/coef.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coef method for ","text":"","code":"if (FALSE) { fit <- plmm(admix$X, admix$y) (coef.plmm(fit)[1:10, 1:5]) # TODO: in R CMD CHECK, this throws the error:  # could not find function \"coef.plmm\" }"},{"path":"/reference/convexMin.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate index for which objective function ceases to be locally convex — convexMin","title":"Calculate index for which objective function ceases to be locally convex — convexMin","text":"Calculate index objective function ceases locally convex","code":""},{"path":"/reference/convexMin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate index for which objective function ceases to be locally convex — convexMin","text":"","code":"convexMin(b, X, penalty, gamma, l2, family = \"gaussian\", penalty.factor)"},{"path":"/reference/convexMin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate index for which objective function ceases to be locally convex — convexMin","text":"b Matrix coefficient values. X Design matrix. penalty penalty applied model. Either \"MCP\", \"SCAD\", \"lasso\". gamma tuning parameter MCP/SCAD penalty. Default 3 MCP 3.7 SCAD. l2 L2. family \"gaussian\" currently supported. penalty.factor multiplicative factor penalty applied coefficient. supplied, penalty.factor must numeric vector length equal number columns X. purpose penalty.factor apply differential penalization coefficients thought likely others model. particular, penalty.factor can 0, case coefficient always model without shrinkage.","code":""},{"path":"/reference/cv.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation for plmm — cv.plmm","title":"Cross-validation for plmm — cv.plmm","text":"Performs k-fold cross validation lasso-, MCP-, SCAD-penalized linear mixed models grid values regularization parameter lambda.","code":""},{"path":"/reference/cv.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation for plmm — cv.plmm","text":"","code":"cv.plmm(   X,   y,   k = NULL,   K = NULL,   diag_K = NULL,   eta_star = NULL,   penalty = c(\"MCP\", \"SCAD\", \"lasso\"),   penalty.factor = rep(1, ncol(X)),   type = \"blup\",   cluster,   nfolds = 10,   seed,   fold = NULL,   returnY = FALSE,   returnBiasDetails = FALSE,   trace = FALSE,   ... )"},{"path":"/reference/cv.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation for plmm — cv.plmm","text":"X Design matrix model fitting. May include clinical covariates non-SNP data. y Continuous outcome vector model fitting. k integer specifying number singular values used approximation rotated design matrix. argument passed RSpectra::eigs(). Defaults min(n, p) - 1, n p dimensions standardized design matrix. K Similarity matrix, form (1) relatedness matrix estimated data (default), (2) user-supplied matrix, (3) user-supplied list components 'd' 'u' created choose_k(). diag_K Logical: K diagonal matrix? reflect observations unrelated, can treated unrelated. Defaults FALSE. eta_star Optional arg. plmm_prep. Defaults NULL. penalty penalty applied model. Either \"MCP\" (default), \"SCAD\", \"lasso\". penalty.factor Optional arg. plmm_prep. Defaults 1 predictors (except intercept). type character argument indicating returned predict.plmm(). type == 'lp' predictions based linear predictor, $X beta$. type == 'blup' predictions based sum linear predictor estimated random effect (BLUP). Defaults 'blup', shown superior prediction method many applications. cluster cv.plmm() can run parallel across cluster using parallel package. cluster must set advance using parallel::makeCluster(). cluster must passed cv.plmm(). nfolds number cross-validation folds. Default 10. seed may set seed random number generator order obtain reproducible results. fold fold observation belongs . default observations randomly assigned. returnY cv.plmm() return linear predictors cross-validation folds? Default FALSE; TRUE, return matrix element row , column j fitted value observation fold observation excluded fit, jth value lambda. returnBiasDetails Logical: cross-validation bias (numeric value) loss (n x p matrix) returned? Defaults FALSE. trace set TRUE, inform user progress announcing beginning CV fold. Default FALSE. ... Additional arguments plmm_fit","code":""},{"path":"/reference/cv.plmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation for plmm — cv.plmm","text":"list 11 items: type: type prediction used ('lp' 'blup') cve: numeric vector cross validation error (CVE) value lambda cvse: numeric vector estimated standard error associated value cve fold: numeric n length vector integers indicating fold observation assigned lambda: numeric vector lambda values fit: overall fit object, including predictors; list returned plmm() min: index corresponding value lambda minimizes cve lambda.min: lambda value cve minmized min1se: index corresponding value lambda within standard error minimizes cve lambda1se: largest value lambda error within 1 standard error minimum. null.dev: numeric value representing deviance intercept-model. supplied lambda sequence, quantity may meaningful.","code":""},{"path":"/reference/cv.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation for plmm — cv.plmm","text":"","code":"cv_fit <- cv.plmm(X = admix$X, y = admix$y, seed = 321) if (FALSE) { cv_s <- summary.cv.plmm(cv_fit, lambda = \"1se\") print(cv_s) plot(cv_fit) }"},{"path":"/reference/cvf.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation internal function for cv.plmm — cvf","title":"Cross-validation internal function for cv.plmm — cvf","text":"Internal function cv.plmm calls plmm fold subset original data.","code":""},{"path":"/reference/cvf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation internal function for cv.plmm — cvf","text":"","code":"cvf(i, fold, type, cv.args, estimated_V, ...)"},{"path":"/reference/cvf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation internal function for cv.plmm — cvf","text":"Fold number excluded fit. fold n-length vector fold-assignments. type character argument indicating returned predict.plmm. type == 'lp' predictions based linear predictor, $X beta$. type == 'individual' predictions based linear predictor plus estimated random effect (BLUP). cv.args List additional arguments passed plmm. estimated_V Estimated variance-covariance matrix using observations computing BLUP; NULL type = \"lp\" cv.plmm. ... Optional arguments predict.list","code":""},{"path":"/reference/delta.html","id":null,"dir":"Reference","previous_headings":"","what":"a helper function to calculate the 'distance' between 2 matrices — delta","title":"a helper function to calculate the 'distance' between 2 matrices — delta","text":"helper function calculate 'distance' 2 matrices","code":""},{"path":"/reference/delta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a helper function to calculate the 'distance' between 2 matrices — delta","text":"","code":"delta(A, B, type = \"F\")"},{"path":"/reference/delta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a helper function to calculate the 'distance' between 2 matrices — delta","text":"matrix compared B B second matrix (think approximation ) type String indicating type norm used. See Matrix::norm() details","code":""},{"path":"/reference/eigen_K.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to take the eigendecomposition of K\nNote: This is faster than taking SVD of X when p >> n — eigen_K","title":"A function to take the eigendecomposition of K\nNote: This is faster than taking SVD of X when p >> n — eigen_K","text":"function take eigendecomposition K Note: faster taking SVD X p >> n","code":""},{"path":"/reference/eigen_K.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to take the eigendecomposition of K\nNote: This is faster than taking SVD of X when p >> n — eigen_K","text":"","code":"eigen_K(std_X, p)"},{"path":"/reference/eigen_K.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to take the eigendecomposition of K\nNote: This is faster than taking SVD of X when p >> n — eigen_K","text":"std_X standardized design matrix p number columns unstandardized design matrix","code":""},{"path":"/reference/eigen_K.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to take the eigendecomposition of K\nNote: This is faster than taking SVD of X when p >> n — eigen_K","text":"list eigenvectors eigenvalues K","code":""},{"path":"/reference/estimate_eta.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate eta (to be used in rotating the data)\nThis function is called internally by plmm() — estimate_eta","title":"Estimate eta (to be used in rotating the data)\nThis function is called internally by plmm() — estimate_eta","text":"Estimate eta (used rotating data) function called internally plmm()","code":""},{"path":"/reference/estimate_eta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate eta (to be used in rotating the data)\nThis function is called internally by plmm() — estimate_eta","text":"","code":"estimate_eta(n, s, U, y, eta_star)"},{"path":"/reference/estimate_eta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate eta (to be used in rotating the data)\nThis function is called internally by plmm() — estimate_eta","text":"n number observations s singular values K, realized relationship matrix U left-singular vectors standardized design matrix y Continuous outcome vector.","code":""},{"path":"/reference/flip_signs.html","id":null,"dir":"Reference","previous_headings":"","what":"a function to check for flipped signs of an SVD — flip_signs","title":"a function to check for flipped signs of an SVD — flip_signs","text":"function check flipped signs SVD","code":""},{"path":"/reference/flip_signs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a function to check for flipped signs of an SVD — flip_signs","text":"","code":"flip_signs(X, U, d, V, svd_list = NULL)"},{"path":"/reference/flip_signs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a function to check for flipped signs of an SVD — flip_signs","text":"X matrix whose SVD UDV^t. SVD may truncated. U matrix left singular vectors d vector singular values V matrix right singular vectors svd_list optional list components u, d, v","code":""},{"path":"/reference/flip_signs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"a function to check for flipped signs of an SVD — flip_signs","text":"Algorithm inspired Bro2007: https://www.osti.gov/servlets/purl/920802","code":""},{"path":"/reference/flip_signs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"a function to check for flipped signs of an SVD — flip_signs","text":"","code":"if (FALSE) { svd_X <- svd(admix$X) svd_X$u[1:3, 1:3] flip_signs(X = admix$X, svd_list = svd_X) -> foo_mat foo_mat$U[1:3, 1:3]  K <- relatedness_mat(admix$X) K[1:4, 1:4] full_svd <- svd(K) full_svd$u[1:4, 1:4] trunc_svd <- RSpectra::svds(K, k = 10) trunc_svd$u[1:4, 1:4] # notice: signs flip (which is a 'bad sign')  # let's fix this:  corrected_trunc_svd <- flip_signs(X = K, svd_list = trunc_svd) corrected_trunc_svd$U[1:4, 1:4]  }"},{"path":"/reference/generate_K.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to generate K matrices for simulation — generate_K","title":"A function to generate K matrices for simulation — generate_K","text":"function generate K matrices simulation","code":""},{"path":"/reference/generate_K.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to generate K matrices for simulation — generate_K","text":"","code":"generate_K(n_per_group, n_groups = 10, mu = 0.7)"},{"path":"/reference/generate_K.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to generate K matrices for simulation — generate_K","text":"n_per_group Number observations per group (e.g., per family, per batch, ...) n_groups Number groups mu Optional vector length n_groups covariance value group. Defaults 0.7 groups. plot Logical: plot K shown? Defaults TRUE.","code":""},{"path":"/reference/generate_K.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to generate K matrices for simulation — generate_K","text":"K matrix","code":""},{"path":"/reference/generate_K.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A function to generate K matrices for simulation — generate_K","text":"internal use running tests","code":""},{"path":"/reference/get_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","title":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","text":"Read processed data function intended called process_plink() called .","code":""},{"path":"/reference/get_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","text":"","code":"get_data(path, returnX, trace = TRUE)"},{"path":"/reference/get_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","text":"path file path RDS object containing processed data. add '.rds' extension path. returnX Logical: design matrix returned numeric matrix stored memory. default, FALSE object sizes exceeds 100 Mb. trace Logical: trace messages shown? Default TRUE.","code":""},{"path":"/reference/get_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","text":"list four components: X, design matrix either (1) numeric matrix (2) filebacked matrix (FBM). See bigstatsr::FBM() bigsnpr::bigSnp-class documentation details. fam, data frame containing pedigree information (like .fam file PLINK) map, data frame containing feature information (like .bim file PLINK)","code":""},{"path":"/reference/get_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","text":"returned list, fam data sorted family individual, dplyr::arrange(family.ID, sample.ID). rows X sorted align order fam, rownames X sample ID.","code":""},{"path":"/reference/get_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read in processed data\nThis function is intended to be called after process_plink() has been called once. — get_data","text":"","code":"if (FALSE) { pen <- get_data(path = \"../temp_files/penncath_lite\", trace = TRUE) }"},{"path":"/reference/gic.html","id":null,"dir":"Reference","previous_headings":"","what":"General information criterion method of selecting lambda for ","title":"General information criterion method of selecting lambda for ","text":"General information criterion method selecting lambda \"plmm\" class","code":""},{"path":"/reference/gic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General information criterion method of selecting lambda for ","text":"","code":"gic(fit, ic = c(\"bic\", \"hdbic\", \"ebic\"), std_X, U, s, eta)"},{"path":"/reference/gic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General information criterion method of selecting lambda for ","text":"fit object class \"plmm\" svd_detail set TRUE (default) ic Information criterion used select lambda. Currently supports BIC HDBIC. Defaults BIC. std_X standardized design matrix U Optional: Left singular eigenvectors X s Optional: Eigenvalues similarity matrix used model fitting. returned part plmm returnX == FALSE, must supplied explicitly. eta Optional: Estimate variance parameter eta","code":""},{"path":"/reference/gic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General information criterion method of selecting lambda for ","text":"","code":"fit <- plmm(X = admix$X, y = admix$y) gic_res <- gic(fit = fit, ic = \"bic\", std_X = ncvreg::std(admix$X)) names(gic_res) #> [1] \"fit\"            \"lambda\"         \"nzero\"          \"gic\"            #> [5] \"lambda.min\"     \"lambda.min.idx\" range(gic_res$gic, na.rm = TRUE) # NAs will result from monomorphic SNPs #> [1] 329.2396 846.9936"},{"path":"/reference/lamNames.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate nicely formatted lambda vec — lamNames","title":"Generate nicely formatted lambda vec — lamNames","text":"Generate nicely formatted lambda vec","code":""},{"path":"/reference/lamNames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate nicely formatted lambda vec — lamNames","text":"","code":"lamNames(l)"},{"path":"/reference/lamNames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate nicely formatted lambda vec — lamNames","text":"l Vector lambda values.","code":""},{"path":"/reference/lamNames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate nicely formatted lambda vec — lamNames","text":"character vector formatted lambda value names","code":""},{"path":"/reference/lmm_ggmix.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a linear mixed model with lasso regularization — lmm_ggmix","title":"Fit a linear mixed model with lasso regularization — lmm_ggmix","text":"function allows fit linear mixed model via lasso-penalized maximum likelihood.","code":""},{"path":"/reference/lmm_ggmix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a linear mixed model with lasso regularization — lmm_ggmix","text":"","code":"lmm_ggmix(X, y, p1, standardize = FALSE, K = NULL)"},{"path":"/reference/lmm_ggmix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a linear mixed model with lasso regularization — lmm_ggmix","text":"X Design matrix. y Continuous outcome vector. p1 Number causal SNPs. Lambda selected <= p1 variables enter model. standardize standardization performed within glmnet()? Defaults FALSE. K Matrix used compute similarity matrix, K. multi-chromosome analysis may supplied order perform leave-one-chromosome-correction. objective adjust population stratification unobserved confounding without rotating causal SNP effects. Default \\(\\frac{1}{p} XX^T\\)","code":""},{"path":"/reference/log_lik.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the negative log-likelihood of an intercept-only Gaussian plmm model — log_lik","title":"Evaluate the negative log-likelihood of an intercept-only Gaussian plmm model — log_lik","text":"function allows evaluate negative log-likelihood linear mixed model assumption null model order estimate variance parameter, eta.","code":""},{"path":"/reference/log_lik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the negative log-likelihood of an intercept-only Gaussian plmm model — log_lik","text":"","code":"log_lik(eta, n, s, U, y, rot_y = NULL)"},{"path":"/reference/log_lik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the negative log-likelihood of an intercept-only Gaussian plmm model — log_lik","text":"eta proportion variance outcome attributable causal SNP effects. words, SNR. Sometimes referred narrow-sense heritability. n number observations s singular values K, realized relationship matrix U left-singular vectors standardized design matrix y Continuous outcome vector. rot_y Optional: y already rotated, can supplied. option designed log_lik() call within gic(), fit object supplied.","code":""},{"path":"/reference/loss.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Loss method for ","title":"Loss method for ","text":"Loss method \"plmm\" class","code":""},{"path":"/reference/loss.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loss method for ","text":"","code":"loss.plmm(y, yhat)"},{"path":"/reference/loss.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loss method for ","text":"y Observed response vector yhat Predicted response vector","code":""},{"path":"/reference/loss.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loss method for ","text":"","code":"fit <- plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X)) yhat <- predict(object = fit, newX = admix$X, type = 'lp', lambda = 0.05) head(loss.plmm(yhat = yhat, y = admix$y)) #>            [,1] #> [1,] 1.82070051 #> [2,] 0.05881704 #> [3,] 0.43397314 #> [4,] 0.56155460 #> [5,] 1.02208056 #> [6,] 0.43364283"},{"path":"/reference/mfdr.html","id":null,"dir":"Reference","previous_headings":"","what":"mfdr: Marginal false discovery rates for PLMMs — mfdr","title":"mfdr: Marginal false discovery rates for PLMMs — mfdr","text":"Based ncvreg::mfdr()","code":""},{"path":"/reference/mfdr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mfdr: Marginal false discovery rates for PLMMs — mfdr","text":"","code":"mfdr(fit)"},{"path":"/reference/mfdr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mfdr: Marginal false discovery rates for PLMMs — mfdr","text":"fit plmm object.","code":""},{"path":"/reference/mfdr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mfdr: Marginal false discovery rates for PLMMs — mfdr","text":"data frame row every value lambda 3 columns: EF: number variables selected given value lambda, averaged permutation fits. S: actual number selected variables non-permuted data. mFDR: estimated marginal false discovery rate (EF/S).","code":""},{"path":"/reference/mfdr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"mfdr: Marginal false discovery rates for PLMMs — mfdr","text":"function estimates marginal false discovery rate (mFDR) penalized regression model. estimate tends accurate settings, slightly conservative predictors highly correlated implemented something like mFDR LMMs yet","code":""},{"path":"/reference/mfdr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mfdr: Marginal false discovery rates for PLMMs — mfdr","text":"","code":"fit <- plmm(admix$X, admix$y) mfdr(fit) |> head() #>                EF  S      mFDR #> 0.42789 -1.000000 -1 1.0000000 #> 0.39905  0.000000  0 0.0000000 #> 0.37215  0.000000  0 0.0000000 #> 0.34707  1.000000  1 1.0000000 #> 0.32368  1.910926  3 0.6369755 #> 0.30187  2.378323  3 0.7927742"},{"path":"/reference/mfdr_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for mFDR — mfdr_plot","title":"Plot method for mFDR — mfdr_plot","text":"Plot method mFDR","code":""},{"path":"/reference/mfdr_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for mFDR — mfdr_plot","text":"","code":"mfdr_plot(mfdr, logscale = TRUE, ...)"},{"path":"/reference/mfdr_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for mFDR — mfdr_plot","text":"mfdr data frame returned mfdr() logscale Logical: lambda values plotted log scale? Defaults TRUE. ... arguments passed plot()","code":""},{"path":"/reference/mfdr_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for mFDR — mfdr_plot","text":"","code":"cv <- cv.plmm(admix$X, admix$y) fit <- cv$fit mfdr_plot(mfdr(fit), type = \"l\")"},{"path":"/reference/pedigree.html","id":null,"dir":"Reference","previous_headings":"","what":"Pedigree: mock genotype data from a family-based design. — pedigree","title":"Pedigree: mock genotype data from a family-based design. — pedigree","text":"mock dataset containing genotypes, family relationships, continuous phenotype dataset inspired one T. Peter's collaborative projects involving analysis congenital disorders family-based data. outcome indicated severity phenotype, higher values -> severe.","code":""},{"path":"/reference/pedigree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pedigree: mock genotype data from a family-based design. — pedigree","text":"","code":"pedigree"},{"path":[]},{"path":"/reference/pedigree.html","id":"pedigree","dir":"Reference","previous_headings":"","what":"pedigree","title":"Pedigree: mock genotype data from a family-based design. — pedigree","text":"list 3 components: X: Design matrix representing 23 family members 5 genes K: Matrix representing family members' relationships expected proportions genetic overlap. Values 0.5 represent parent-child sibling relationships; see data-raw/pedigree.R details. Note: correlation matrix. Use cov2cor() similar function obtain correlations. clinical: data frame 23 observations 3 variables: sample.id integer indicating sample.id (IID PLINK .fam file) sex biological sex participant (just like PLINK, 2 = female & 1 = male) y numeric value corresponding phenotype severity","code":""},{"path":"/reference/plink_example.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to help with accessing example PLINK files — plink_example","title":"A function to help with accessing example PLINK files — plink_example","text":"function help accessing example PLINK files","code":""},{"path":"/reference/plink_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to help with accessing example PLINK files — plink_example","text":"","code":"plink_example(path, parent = FALSE)"},{"path":"/reference/plink_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to help with accessing example PLINK files — plink_example","text":"path Argument (string) specifying path (filename) external data file extdata/ parent path=TRUE user wants name parent directory file located, set parent=TRUE. Defaults FALSE.","code":""},{"path":"/reference/plink_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to help with accessing example PLINK files — plink_example","text":"path=NULL, character vector file names returned. path given, character string full file path","code":""},{"path":"/reference/plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a linear mixed model with non-convex regularization — plmm","title":"Fit a linear mixed model with non-convex regularization — plmm","text":"function allows fit linear mixed model via non-convex penalized maximum likelihood. NB: function simply wrapper plmm_prep -> plmm_fit -> plmm_format","code":""},{"path":"/reference/plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a linear mixed model with non-convex regularization — plmm","text":"","code":"plmm(   X,   y,   k = NULL,   K = NULL,   diag_K = NULL,   eta_star = NULL,   penalty = c(\"MCP\", \"SCAD\", \"lasso\"),   gamma,   alpha = 1,   lambda.min,   nlambda = 100,   lambda,   eps = 1e-04,   max.iter = 10000,   convex = TRUE,   dfmax = ncol(X) + 1,   warn = TRUE,   penalty.factor = rep(1, ncol(X)),   init = rep(0, ncol(X)),   trace = FALSE )"},{"path":"/reference/plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a linear mixed model with non-convex regularization — plmm","text":"X Design matrix object string file path design matrix. string, string passed get_data(). Note: X may include clinical covariates non-SNP data, missing values allowed. y Continuous outcome vector. Logistic regression modeling still development. k integer specifying number singular values used approximation rotated design matrix. argument passed RSpectra::svds(). Defaults min(n, p) - 1, n p dimensions standardized design matrix. K Similarity matrix used rotate data. either (1) known matrix reflects covariance y, (2) estimate (Default realized relatedness matrix), (3) list components 'd' 'u', returned choose_k(). diag_K Logical: K diagonal matrix? reflect observations unrelated, can treated unrelated. Defaults FALSE. Note: plmm() check see matrix diagonal. want use diagonal K matrix, must set diag_K = TRUE. eta_star Optional argument input specific eta term rather estimate data. K known covariance matrix full rank, 1. penalty penalty applied model. Either \"MCP\" (default), \"SCAD\", \"lasso\". gamma tuning parameter MCP/SCAD penalty (see details). Default 3 MCP 3.7 SCAD. alpha Tuning parameter Mnet estimator controls relative contributions MCP/Spenncath penalty ridge, L2 penalty. alpha=1 equivalent MCP/Spenncath penalty, alpha=0 equivalent ridge regression. However, alpha=0 supported; alpha may arbitrarily small, exactly 0. lambda.min smallest value lambda, fraction lambda.max. Default .001 number observations larger number covariates .05 otherwise. nlambda Length sequence lambda. Default 100. lambda user-specified sequence lambda values. default, sequence values length nlambda computed, equally spaced log scale. eps Convergence threshold. algorithm iterates RMSD change linear predictors coefficient less eps. Default 1e-4. max.iter Maximum number iterations (total across entire path). Default 10000. convex Calculate index objective function ceases locally convex? Default TRUE. dfmax Upper bound number nonzero coefficients. Default upper bound. However, large data sets, computational burden may heavy models large number nonzero coefficients. warn Return warning messages failures converge model saturation? Default TRUE. penalty.factor multiplicative factor penalty applied coefficient. supplied, penalty.factor must numeric vector length equal number columns X. purpose penalty.factor apply differential penalization coefficients thought likely others model. particular, penalty.factor can 0, case coefficient always model without shrinkage. init Initial values coefficients. Default 0 columns X. trace set TRUE, inform user progress announcing beginning step modeling process. Default FALSE.","code":""},{"path":"/reference/plmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a linear mixed model with non-convex regularization — plmm","text":"list includes: beta_vals: matrix estimated coefficients original scale. Rows predictors, columns values lambda rotated_scale_beta_vals: matrix estimated coefficients ~rotated~ scale. scale model fit. lambda: numeric vector lasso tuning parameter values used model fitting. eta: number (double) 0 1 representing estimated proportion variance outcome attributable population/correlation structure. s: vectof eigenvalues relatedness matrix K; see relatedness_mat() details. U: matrix eigenvalues relatedness matrix K rot_y: vector outcome values rotated scale. scale model fit. linear.predictors: matrix resulting product stdrot_X estimated coefficients ~rotated~ scale. penalty: character string indicating penalty model fit (e.g., 'MCP') gamma: numeric value indicating tuning parameter used SCAD lasso penalties used. relevant lasso models. alpha: numeric value indicating elastic net tuning parameter. convex.min: NULL (option add future!) loss: vector numeric values loss value lambda (calculated ~rotated~ scale) penalty.factor: vector indicators corresponding predictor, 1 = predictor penalized. ns_idx: vector indicies predictors constant features (.e., variation). p: number features n: number observations (instances) iter: numeric vector number iterations needed model fitting value lambda converged: vector logical values indicating whether model fitting converged value lambda","code":""},{"path":"/reference/plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a linear mixed model with non-convex regularization — plmm","text":"","code":"# using admix data  fit_admix1 <- plmm(X = admix$X, y = admix$y) s1 <- summary(fit_admix1, idx = 99) print(s1) #> MCP-penalized regression model with n=197, p=101 at lambda=0.00046 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  98  #> ------------------------------------------------- plot(fit_admix1)   # an example with p > n: fit_admix2 <- plmm(X = admix$X[1:50, ], y = admix$y[1:50]) s2 <- summary(fit_admix2, idx = 99) print(s2) #> MCP-penalized regression model with n=50, p=101 at lambda=0.0402 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  30  #> ------------------------------------------------- plot(fit_admix2) # notice: the default penalty is MCP"},{"path":"/reference/plmm_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"PLMM fit: a function that fits a PLMM using the values returned by plmm_prep()\nThis is an internal function for cv.plmm — plmm_fit","title":"PLMM fit: a function that fits a PLMM using the values returned by plmm_prep()\nThis is an internal function for cv.plmm — plmm_fit","text":"PLMM fit: function fits PLMM using values returned plmm_prep() internal function cv.plmm","code":""},{"path":"/reference/plmm_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PLMM fit: a function that fits a PLMM using the values returned by plmm_prep()\nThis is an internal function for cv.plmm — plmm_fit","text":"","code":"plmm_fit(   prep,   penalty = \"MCP\",   gamma,   alpha = 1,   lambda.min,   nlambda = 100,   lambda,   eps = 1e-04,   max.iter = 10000,   convex = TRUE,   dfmax = prep$p + 1,   init = NULL,   warn = TRUE,   returnX = TRUE )"},{"path":"/reference/plmm_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PLMM fit: a function that fits a PLMM using the values returned by plmm_prep()\nThis is an internal function for cv.plmm — plmm_fit","text":"prep list returned plmm_prep penalty penalty applied model. Either \"MCP\" (default), \"SCAD\", \"lasso\". gamma tuning parameter MCP/SCAD penalty (see details). Default 3 MCP 3.7 SCAD. alpha Tuning parameter Mnet estimator controls relative contributions MCP/SCAD penalty ridge, L2 penalty. alpha=1 equivalent MCP/SCAD penalty, alpha=0 equivalent ridge regression. However, alpha=0 supported; alpha may arbitrarily small, exactly 0. lambda.min smallest value lambda, fraction lambda.max. Default .001 number observations larger number covariates .05 otherwise. nlambda Length sequence lambda. Default 100. lambda user-specified sequence lambda values. default, sequence values length nlambda computed, equally spaced log scale. eps Convergence threshold. algorithm iterates RMSD change linear predictors coefficient less eps. Default 1e-4. max.iter Maximum number iterations (total across entire path). Default 10000. convex convex Calculate index objective function ceases locally convex? Default TRUE. dfmax (future idea; yet incorporated) Upper bound number nonzero coefficients. Default upper bound. However, large data sets, computational burden may heavy models large number nonzero coefficients. init Initial values coefficients. Default 0 columns X. warn Return warning messages failures converge model saturation? Default TRUE. returnX Return standardized design matrix along fit? default, option turned X 100 MB, turned larger matrices preserve memory.","code":""},{"path":"/reference/plmm_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PLMM fit: a function that fits a PLMM using the values returned by plmm_prep()\nThis is an internal function for cv.plmm — plmm_fit","text":"list components: n: # rows X p: # columns X (including constant features) y: outcome original scale std_X_details: list 'center' 'scale' vectors, plmm_prep() s: eigenvalues K U: eigenvectors K rot_X: X rotated (.e., transformed) scale. Note dimensions rot_X likely different X. rot_y: y rotated scale stdrot_X: X rotated scale re-standardized. lambda: vector tuning parameter values b: coefficients estimated scale stdrot_X untransformed_b1: coefficients estimated scale std_X linear.predictors: product stdrot_X b (linear predictors transformed restandardized scale) eta: number (double) 0 1 representing estimated proportion variance outcome attributable population/correlation structure. iter: numeric vector number iterations needed model fitting value lambda converged: vector logical values indicating whether model fitting converged value lambda loss: vector numeric values loss value lambda (calculated ~rotated~ scale) penalty: character string indicating penalty model fit (e.g., 'MCP') penalty.factor: vector indicators corresponding predictor, 1 = predictor penalized. gamma: numeric value indicating tuning parameter used SCAD lasso penalties used. relevant lasso models. alpha: numeric value indicating elastic net tuning parameter. ns: indices nonsingular values X snp_names: ormatted column names design matrix nlambda: number lambda values used model fitting eps: tolerance ('epsilon') used model fitting max.iter: max. number iterations per model fit warn: logical - warnings given model fit converge? init: initial values model fitting trace: logical - messages printed console models fit?","code":""},{"path":"/reference/plmm_format.html","id":null,"dir":"Reference","previous_headings":"","what":"PLMM format: a function to format the output of a model constructed with plmm_fit — plmm_format","title":"PLMM format: a function to format the output of a model constructed with plmm_fit — plmm_format","text":"PLMM format: function format output model constructed plmm_fit","code":""},{"path":"/reference/plmm_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PLMM format: a function to format the output of a model constructed with plmm_fit — plmm_format","text":"","code":"plmm_format(fit, X)"},{"path":"/reference/plmm_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PLMM format: a function to format the output of a model constructed with plmm_fit — plmm_format","text":"fit list parameters describing output model constructed plmm_fit X Design matrix. May include clinical covariates non-SNP data.","code":""},{"path":"/reference/plmm_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PLMM format: a function to format the output of a model constructed with plmm_fit — plmm_format","text":"list components: beta_vals: matrix estimated coefficients original scale. Rows predictors, columns values lambda rotated_scale_beta_vals: matrix estimated coefficients ~rotated~ scale. scale model fit. lambda: numeric vector lasso tuning parameter values used model fitting. eta: number (double) 0 1 representing estimated proportion variance outcome attributable population/correlation structure. s: vectof eigenvalues relatedness matrix K; see relatedness_mat() details. U: matrix eigenvalues relatedness matrix K rot_y: vector outcome values rotated scale. scale model fit. linear.predictors: matrix resulting product stdrot_X estimated coefficients ~rotated~ scale. penalty: character string indicating penalty model fit (e.g., 'MCP') gamma: numeric value indicating tuning parameter used SCAD lasso penalties used. relevant lasso models. alpha: numeric value indicating elastic net tuning parameter. convex.min: NULL (option add future!) loss: vector numeric values loss value lambda (calculated ~rotated~ scale) penalty.factor: vector indicators corresponding predictor, 1 = predictor penalized. ns_idx: vector indicies predictors constant features (.e., variation). p: number features n: number observations (instances) iter: numeric vector number iterations needed model fitting value lambda converged: vector logical values indicating whether model fitting converged value lambda","code":""},{"path":"/reference/plmm_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"PLMM prep: a function to run checks, SVD, and rotation prior to fitting a PLMM model\nThis is an internal function for cv.plmm — plmm_prep","title":"PLMM prep: a function to run checks, SVD, and rotation prior to fitting a PLMM model\nThis is an internal function for cv.plmm — plmm_prep","text":"PLMM prep: function run checks, SVD, rotation prior fitting PLMM model internal function cv.plmm","code":""},{"path":"/reference/plmm_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PLMM prep: a function to run checks, SVD, and rotation prior to fitting a PLMM model\nThis is an internal function for cv.plmm — plmm_prep","text":"","code":"plmm_prep(   X,   y,   k = NULL,   K = NULL,   diag_K = NULL,   eta_star = NULL,   penalty.factor = rep(1, ncol(X)),   trace = NULL,   ... )"},{"path":"/reference/plmm_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PLMM prep: a function to run checks, SVD, and rotation prior to fitting a PLMM model\nThis is an internal function for cv.plmm — plmm_prep","text":"X Design matrix. May include clinical covariates non-SNP data. y Continuous outcome vector. k integer specifying number singular values used approximation rotated design matrix. argument passed RSpectra::svds(). Defaults min(n, p) - 1, n p dimensions standardized design matrix. K Similarity matrix used rotate data. either known matrix reflects covariance y, estimate (Default \\(\\frac{1}{p}(XX^T)\\), X standardized). can also list, components d u (returned choose_k) diag_K Logical: K diagonal matrix? reflect observations unrelated, can treated unrelated. Passed plmm(). eta_star Optional argument input specific eta term rather estimate data. K known covariance matrix full rank, 1. penalty.factor multiplicative factor penalty applied coefficient. supplied, penalty.factor must numeric vector length equal number columns X. purpose penalty.factor apply differential penalization coefficients thought likely others model. particular, penalty.factor can 0, case coefficient always model without shrinkage. trace set TRUE, inform user progress announcing beginning step modeling process. Default FALSE. ... used yet","code":""},{"path":"/reference/plmm_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PLMM prep: a function to run checks, SVD, and rotation prior to fitting a PLMM model\nThis is an internal function for cv.plmm — plmm_prep","text":"List components: n: number rows original design matrix p: number columns original design matrix y: vector outcomes std_X: standardized design matrix std_X_details: list 2 vectors: 'center' (values used center X) 'scale' (values used scale X) s: vector eigenvalues K U: eigenvectors K (left singular values X). ns: indices nonsingular values X penalty.factor: penalty factors penalized non-singular values snp_names: formatted column names design matrix","code":""},{"path":"/reference/plmm_prep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PLMM prep: a function to run checks, SVD, and rotation prior to fitting a PLMM model\nThis is an internal function for cv.plmm — plmm_prep","text":"","code":"if (FALSE) { # this is an internal function; to call this, you would need to use the triple  # colon, e.g., plmmr:::plmm_prep() prep1 <- plmm_prep(X = admix$X, y = admix$y, trace = TRUE) prep2 <- plmm_prep(X = admix$X, y = admix$y, diag_K = TRUE, trace = TRUE) }"},{"path":"/reference/plmmr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"plmmr: Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects — plmmr-package","title":"plmmr: Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects — plmmr-package","text":"Fits penalized linear mixed models correct unobserved confounding factors. 'plmmr' infers corrects presence unobserved confounding effects population stratification environmental heterogeneity. fits linear model via penalized maximum likelihood. Originally designed multivariate analysis SNP data, 'plmmr' eliminates need subpopulation-specific analyses post-analysis p-value adjustments. Functions appropriate processing 'PLINK' files also supplied. examples, see package homepage https://pbreheny.github.io/plmmr/.","code":""},{"path":"/reference/plmmr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"plmmr: Fit nonconvex-penalized linear mixed models to account for the presence of unobserved confounding effects — plmmr-package","text":"Maintainer: Tabitha K. Peter tabitha-peter@uiowa.edu (ORCID) Authors: Anna C. Reisetter anna-reisetter@uiowa.edu (ORCID) Patrick J. Breheny (ORCID) Yujing Lu","code":""},{"path":"/reference/plot.cv.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for cv.plmm class — plot.cv.plmm","title":"Plot method for cv.plmm class — plot.cv.plmm","text":"Plot method cv.plmm class","code":""},{"path":"/reference/plot.cv.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for cv.plmm class — plot.cv.plmm","text":"","code":"# S3 method for cv.plmm plot(   x,   log.l = TRUE,   type = c(\"cve\", \"rsq\", \"scale\", \"snr\", \"all\"),   selected = TRUE,   vertical.line = TRUE,   col = \"red\",   ... )"},{"path":"/reference/plot.cv.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for cv.plmm class — plot.cv.plmm","text":"x object class cv.plmm log.l Logical indicate plot returned natural log scale. Defaults log.l = FALSE. type Type plot return. Defaults \"cve.\" selected Logical indicate variables plotted. Defaults TRUE. vertical.line Logical indicate whether vertical line plotted minimum/maximum value. Defaults TRUE. col Color vertical line, plotted. Defaults \"red.\" ... Additional arguments.","code":""},{"path":"/reference/plot.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for plmm class — plot.plmm","title":"Plot method for plmm class — plot.plmm","text":"Plot method plmm class","code":""},{"path":"/reference/plot.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for plmm class — plot.plmm","text":"","code":"# S3 method for plmm plot(x, alpha = 1, log.l = FALSE, shade = TRUE, col, ...)"},{"path":"/reference/plot.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for plmm class — plot.plmm","text":"x object class plmm alpha Tuning parameter Mnet estimator controls relative contributions MCP/SCAD penalty ridge, L2 penalty. alpha=1 equivalent MCP/SCAD penalty, alpha=0 equivalent ridge regression. However, alpha=0 supported; alpha may arbitrarily small, exactly 0. log.l Logical indicate plot returned natural log scale. Defaults log.l = FALSE. shade Logical indicate whether local nonconvex region shaded. Defaults TRUE. col Vector colors coefficient lines. ... Additional arguments.","code":""},{"path":"/reference/plot.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for plmm class — plot.plmm","text":"","code":"fit <- plmm(admix$X[,1:10], admix$y, nlambda = 10) # for the sake of illustration, I consider only 10 SNPs in the plot  plot(fit)  plot(fit, log.l = TRUE)"},{"path":"/reference/predict.list.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for a list used in cross-validation (within cvf) — predict.list","title":"Predict method for a list used in cross-validation (within cvf) — predict.list","text":"Predict method list used cross-validation (within cvf)","code":""},{"path":"/reference/predict.list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for a list used in cross-validation (within cvf) — predict.list","text":"","code":"# S3 method for list predict(   fit,   oldX,   newX,   type = c(\"lp\", \"blup\"),   idx = 1:length(fit$lambda),   V11 = NULL,   V21 = NULL,   ... )"},{"path":"/reference/predict.list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for a list used in cross-validation (within cvf) — predict.list","text":"fit list components returned plmm_fit. oldX standardized design matrix training data, pre-rotation. newX design matrix used computing predicted values (.e, test data). type character argument indicating type prediction returned. Options \"lp,\" \"coefficients,\" \"vars,\" \"nvars,\" \"blup.\" See details. idx Vector indices penalty parameter lambda predictions required. default, indices returned. V11 Variance-covariance matrix training data. Extracted estimated_V generated using observations. Required type == 'blup'. V21 Covariance matrix training testing data. Extracted estimated_V generated using observations. Required type == 'blup'. ... Additional optional arguments","code":""},{"path":"/reference/predict.list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict method for a list used in cross-validation (within cvf) — predict.list","text":"Define beta-hat coefficients estimated value lambda minimizes cross-validation error (CVE). options type follows: 'lp' (default): uses linear predictor (.e., product new data estimated coefficients) predict new values outcome. Note approach incorporate correlation structure data. 'blup' (acronym Best Linear Unbiased Predictor): adds 'lp' value represents estimated random effect. addition way incorporating estimated correlation structure data prediction outcome.","code":""},{"path":"/reference/predict.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for plmm class — predict.plmm","title":"Predict method for plmm class — predict.plmm","text":"Predict method plmm class","code":""},{"path":"/reference/predict.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for plmm class — predict.plmm","text":"","code":"# S3 method for plmm predict(   object,   newX,   type = c(\"lp\", \"coefficients\", \"vars\", \"nvars\", \"blup\"),   lambda,   idx = 1:length(object$lambda),   X,   y,   K = NULL,   ... )"},{"path":"/reference/predict.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for plmm class — predict.plmm","text":"object object class plmm. newX Design matrix used computing predicted values requested. Columns must named! type character argument indicating type prediction returned. Options \"lp,\" \"coefficients,\" \"vars,\" \"nvars,\" \"blup.\" See details. lambda numeric vector regularization parameter lambda values predictions requested. idx Vector indices penalty parameter lambda predictions required. default, indices returned. X Original design matrix (including intercept column) object. Required type == 'blup' object large returned plmm object. , columns must named! y Original continuous outcome vector object. Required type == 'blup'. K optional list matrix returned choose_K(). ... Additional optional arguments","code":""},{"path":"/reference/predict.plmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict method for plmm class — predict.plmm","text":"Define beta-hat coefficients estimated value lambda minimizes cross-validation error (CVE). options type follows: 'response' (default): uses product newX beta-hat predict new values outcome. incorporate correlation structure data. stats folks , simply linear predictor. 'blup' (acronym Best Linear Unbiased Predictor): adds 'response' value represents esetimated random effect. addition way incorporating estimated correlation structure data prediction outcome. 'coefficients': returns estimated beta-hat 'vars': returns indicies variables (e.g., SNPs) nonzero coefficients value lambda. EXCLUDES intercept. 'nvars': returns number variables (e.g., SNPs) nonzero coefficients value lambda. EXCLUDES intercept.","code":""},{"path":"/reference/predict.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict method for plmm class — predict.plmm","text":"","code":"if (FALSE) { # fit a model  fit <- plmm(X = admix$X, y = admix$y) lp_pred <- predict(fit, newX = admix$X, type = 'lp') blup_pred <- predict(fit, newX = admix$X, X = admix$X, y = admix$y) # BLUP is default type lp_mspe <- apply(lp_pred, 2, function(c){crossprod(admix$y - c)}) min(lp_mspe)  blup_mspe <- apply(blup_pred, 2, function(c){crossprod(admix$y - c)}) min(blup_mspe)  cv_fit <- cv.plmm(X = admix$X, y = admix$y) min(cv_fit$cve)   set.seed(123) train_idx <- sample(1:nrow(admix$X), 100) # shuffling is important here! Keeps test and train groups comparable. train <- list(X = admix$X[train_idx,], y = admix$y[train_idx]) test <- list(X = admix$X[-train_idx,], y = admix$y[-train_idx]) fit <- plmm(X = train$X, y = train$y, K = relatedness_mat(train$X))   # make predictions for all lambda values   pred1 <- predict(object = fit, newX = test$X, type = \"blup\", X = train$X, y = train$y)   # make predictions for a select number of lambda values  # use cv to choose a best lambda  cvfit <- cv.plmm(X = train$X, y = train$y)   pred2 <- predict(object = fit, newX = test$X, type = \"blup\", idx=cvfit$min,   X = train$X, y = train$y)  pred3 <- predict(object = fit, newX = test$X, type = \"lp\", idx=cvfit$min)      # examine prediction error    summary(crossprod(test$y - pred2))  # for BLUP method    summary(crossprod(test$y - pred3)) # for LP method       # which was best prediction?   mspe <- apply(pred1, 2, function(c){crossprod(test$y - c)})   which.min(mspe) # not anywhere near the 'best lambda' chosen in cross validation...   mspe[which.min(mspe)]   min(cvfit$cve)  }"},{"path":"/reference/print.summary.cv.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for summary.cv.plmm objects — print.summary.cv.plmm","title":"Print method for summary.cv.plmm objects — print.summary.cv.plmm","text":"Print method summary.cv.plmm objects","code":""},{"path":"/reference/print.summary.cv.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for summary.cv.plmm objects — print.summary.cv.plmm","text":"","code":"# S3 method for summary.cv.plmm print(x, digits, ...)"},{"path":"/reference/print.summary.cv.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for summary.cv.plmm objects — print.summary.cv.plmm","text":"x object class summary.cv.plmm digits number digits use formatting output ... used","code":""},{"path":"/reference/print.summary.cv.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for summary.cv.plmm objects — print.summary.cv.plmm","text":"","code":"cv_fit <- cv.plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X)) print(summary(cv_fit)) #> MCP-penalized model with n=197 and p=100 #> At minimum cross-validation error (lambda=0.4279): #> ------------------------------------------------- #>   Nonzero coefficients: 0 #>   Cross-validation error (deviance): 2.04 #>   Scale estimate (sigma): 1.428"},{"path":"/reference/print.summary.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to print the summary of a plmm model — print.summary.plmm","title":"A function to print the summary of a plmm model — print.summary.plmm","text":"function print summary plmm model","code":""},{"path":"/reference/print.summary.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to print the summary of a plmm model — print.summary.plmm","text":"","code":"# S3 method for summary.plmm print(x, ...)"},{"path":"/reference/print.summary.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to print the summary of a plmm model — print.summary.plmm","text":"x summary.plmm object ... used","code":""},{"path":"/reference/print.summary.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to print the summary of a plmm model — print.summary.plmm","text":"","code":"fit <- plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X)) fit2 <- plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X), penalty = \"SCAD\") s1 <- summary(fit, idx = 97) s2 <- summary(fit, lambda = fit$lambda[97]) s3 <- summary(fit2, idx = 25) print(s1) #> MCP-penalized regression model with n=197, p=101 at lambda=0.00053 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  98  #> ------------------------------------------------- print(s2) #> MCP-penalized regression model with n=197, p=101 at lambda=0.00053 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  98  #> ------------------------------------------------- print(s3) #> SCAD-penalized regression model with n=197, p=101 at lambda=0.08018 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  43  #> -------------------------------------------------"},{"path":"/reference/process_plink.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess PLINK files using the bigsnpr package — process_plink","title":"Preprocess PLINK files using the bigsnpr package — process_plink","text":"Preprocess PLINK files using bigsnpr package","code":""},{"path":"/reference/process_plink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess PLINK files using the bigsnpr package — process_plink","text":"","code":"process_plink(   data_dir,   prefix,   impute = TRUE,   impute_method = \"mode\",   quiet = FALSE,   gz = FALSE,   outfile,   ... )"},{"path":"/reference/process_plink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess PLINK files using the bigsnpr package — process_plink","text":"data_dir path bed/bim/fam data files prefix prefix (character string) bed/fam data files impute Logical: data imputed? Default TRUE. impute_method 'impute' = TRUE, argument specify kind imputation desired. Options : mode (default): Imputes frequent call. See bigsnpr::snp_fastImputeSimple() details. random: Imputes sampling according allele frequencies. mean0: Imputes rounded mean. mean2: Imputes mean rounded 2 decimal places. xgboost: Imputes using algorithm based local XGBoost models. See bigsnpr::snp_fastImpute() details. Note: can take several minutes, even relatively small data set. quiet Logical: messages printed console? Defaults TRUE gz Logical: bed/bim/fam files g-zipped? Defaults FALSE. NOTE: TRUE, process_plink unzip zipped files. outfile Optional: name (character string) prefix logfile written. Defaults 'process_plink', .e. get 'process_plink.log' outfile. ... Optional: additional arguments bigsnpr::snp_fastImpute() (relevant impute_method = \"xgboost\")","code":""},{"path":"/reference/process_plink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess PLINK files using the bigsnpr package — process_plink","text":"Nothing returned function; instead, files 'prefix.rds' 'prefix.bk' created location specified data_dir. Note function need run ; subsequent data analysis/scripts, get_data() access '.rds' file.","code":""},{"path":"/reference/process_plink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess PLINK files using the bigsnpr package — process_plink","text":"","code":"if (FALSE) { process_plink(data_dir = \"../temp_files\",  prefix = \"penncath_lite\",   impute = T,    quiet = F) }"},{"path":"/reference/relatedness_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a relatedness matrix — relatedness_mat","title":"Calculate a relatedness matrix — relatedness_mat","text":"function allows generate n n genetic relatedness matrix. numeric matrix supplied, RRM (Hayes, 2009) used computed XX'/p, X standardized.","code":""},{"path":"/reference/relatedness_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a relatedness matrix — relatedness_mat","text":"","code":"relatedness_mat(X, std = TRUE)"},{"path":"/reference/relatedness_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a relatedness matrix — relatedness_mat","text":"X numeric matrix genotypes (fully-imputed data) std Logical: X standardized? set FALSE, know exactly appropriate... standardization best practice, impact results.","code":""},{"path":"/reference/relatedness_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a relatedness matrix — relatedness_mat","text":"","code":"RRM <- relatedness_mat(X = admix$X)"},{"path":"/reference/residuals.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract residuals from a PLMM fit — residuals.plmm","title":"Extract residuals from a PLMM fit — residuals.plmm","text":"Currently, deviance residuals supported.","code":""},{"path":"/reference/residuals.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract residuals from a PLMM fit — residuals.plmm","text":"","code":"# S3 method for plmm residuals(   object,   lambda,   which = 1:length(object$lambda),   drop = TRUE,   unrotate = FALSE,   ... )"},{"path":"/reference/residuals.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract residuals from a PLMM fit — residuals.plmm","text":"object Object class plmm. lambda Values regularization parameter residuals requested (numeric vector). values lambda sequence fitted models, linear interpolation used. Index penalty parameter residuals requested (default = indices). lambda specified, take precedence . drop default, single value lambda supplied, vector residuals returned (logical; default=TRUE). Set drop=FALSE wish function always return matrix (see drop()). unrotate Logical: residuals 'unrotated', .e. transformed back original scale? ... used.","code":""},{"path":"/reference/residuals.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract residuals from a PLMM fit — residuals.plmm","text":"","code":"if (FALSE) { fit <- plmm(admix$X, admix$y) residuals.plmm(fit)[1:5, 1:5] head(residuals.plmm(fit, which = 50)) }"},{"path":"/reference/rotate.html","id":null,"dir":"Reference","previous_headings":"","what":"a function to rotate data (or 'precondition' data) onto the transformed scale — rotate","title":"a function to rotate data (or 'precondition' data) onto the transformed scale — rotate","text":"function rotate data ('precondition' data) onto transformed scale","code":""},{"path":"/reference/rotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a function to rotate data (or 'precondition' data) onto the transformed scale — rotate","text":"","code":"rotate(s, U, eta, y = NULL, X = NULL)"},{"path":"/reference/rotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a function to rotate data (or 'precondition' data) onto the transformed scale — rotate","text":"s vector eigenvalues X U left singular vectors X eta estimated variance parameter y vector outcomes X design matrix","code":""},{"path":"/reference/scale_varp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate scale by the population standard deviation, without centering — scale_varp","title":"Calculate scale by the population standard deviation, without centering — scale_varp","text":"function allows scale vectors matrix population standard deviation without centering; assume sample population.","code":""},{"path":"/reference/scale_varp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate scale by the population standard deviation, without centering — scale_varp","text":"","code":"scale_varp(X)"},{"path":"/reference/scale_varp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate scale by the population standard deviation, without centering — scale_varp","text":"X numeric matrix","code":""},{"path":"/reference/scale_varp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate scale by the population standard deviation, without centering — scale_varp","text":"","code":"if (FALSE) { M <- matrix(rnorm(25), 5, 5) head(M) M_scaled <- scale_varp(M) head(M_scaled)  X_scaled <- scale_varp(admix$X) admix$X[1:5, 1:7]; X_scaled[1:5, 1:7] }"},{"path":"/reference/setup_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute sequence of lambda values — setup_lambda","title":"Compute sequence of lambda values — setup_lambda","text":"function allows compute sequence lambda values plmm models.","code":""},{"path":"/reference/setup_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute sequence of lambda values — setup_lambda","text":"","code":"setup_lambda(   X,   y,   alpha,   lambda.min,   nlambda,   penalty.factor,   intercept = TRUE )"},{"path":"/reference/setup_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute sequence of lambda values — setup_lambda","text":"X Rotated standardized design matrix includes intercept column present. May include clinical covariates non-SNP data. y Continuous outcome vector. alpha Tuning parameter Mnet estimator controls relative contributions MCP/SCAD penalty ridge, L2 penalty. alpha=1 equivalent MCP/SCAD penalty, alpha=0 equivalent ridge regression. However, alpha=0 supported; alpha may arbitrarily small, exactly 0. lambda.min smallest value lambda, fraction lambda.max. Default .001 number observations larger number covariates .05 otherwise. value lambda.min = 0 supported. nlambda desired number lambda values sequence generated. penalty.factor multiplicative factor penalty applied coefficient. supplied, penalty.factor must numeric vector length equal number columns X. purpose penalty.factor apply differential penalization coefficients thought likely others model. particular, penalty.factor can 0, case coefficient always model without shrinkage. intercept Logical: X contain intercept column? Defaults TRUE.","code":""},{"path":"/reference/setup_lambda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute sequence of lambda values — setup_lambda","text":"","code":"if (FALSE) { RRM <- relatedness_mat(X = scale(admix$X)) fit <- plmm_lasso(X = admix$X, y = admix$y, K = RRM, p1 = 10) (setup_lambda(admix$X, admix$y, alpha = 0.1, nlambda = 10,  penalty.factor = fit$penalty.factor)) # use default lambda.min }"},{"path":"/reference/summary.cv.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"A summary function for cv.plmm objects — summary.cv.plmm","title":"A summary function for cv.plmm objects — summary.cv.plmm","text":"summary function cv.plmm objects","code":""},{"path":"/reference/summary.cv.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A summary function for cv.plmm objects — summary.cv.plmm","text":"","code":"# S3 method for cv.plmm summary(object, lambda = \"min\", ...)"},{"path":"/reference/summary.cv.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A summary function for cv.plmm objects — summary.cv.plmm","text":"object cv.plmm object lambda regularization parameter value inference reported. Can choose numeric value, 'min', '1se'. Defaults 'min.' ... used","code":""},{"path":"/reference/summary.cv.plmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A summary function for cv.plmm objects — summary.cv.plmm","text":"return value object S3 class summary.cv.plmm. class print method contains following list elements: lambda.min: lambda value minimum cross validation error lambda.1se: maximum lambda value within 1 standard error minimum cross validation error nvars: number non-zero coefficients selected lambda value cve: cross validation error folds min: minimum cross validation error fit: plmm fit used cross validation bias: mean bias cross validation loss: loss (fold?) TODO: double-check penalty: penalty applied fitted model","code":""},{"path":"/reference/summary.cv.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A summary function for cv.plmm objects — summary.cv.plmm","text":"","code":"cv_fit <- cv.plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X)) summary(cv_fit) #> MCP-penalized model with n=197 and p=100 #> At minimum cross-validation error (lambda=0.4279): #> ------------------------------------------------- #>   Nonzero coefficients: 0 #>   Cross-validation error (deviance): 2.07 #>   Scale estimate (sigma): 1.440"},{"path":"/reference/summary.plmm.html","id":null,"dir":"Reference","previous_headings":"","what":"A summary method for the plmm objects — summary.plmm","title":"A summary method for the plmm objects — summary.plmm","text":"summary method plmm objects","code":""},{"path":"/reference/summary.plmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A summary method for the plmm objects — summary.plmm","text":"","code":"# S3 method for plmm summary(object, lambda, idx, eps = 1e-05, ...)"},{"path":"/reference/summary.plmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A summary method for the plmm objects — summary.plmm","text":"object object class plmm lambda regularization parameter value inference reported. idx Alternatively, lambda may specified index; idx=10 means: report inference 10th value lambda along regularization path. lambda idx specified, lambda takes precedence. eps lambda given, eps tolerance difference given lambda value lambda value object. Defaults 0.0001 (1e-5) ... used","code":""},{"path":"/reference/summary.plmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A summary method for the plmm objects — summary.plmm","text":"return value object S3 class summary.plmm. class print method contains following list elements: penalty: penalty used plmm (e.g. SCAD, MCP, lasso) n: Number instances/observations p: Number regression coefficients (including intercept) converged: Logical indicator whether model converged lambda: lambda value inference reported lambda_char: formatted character string indicating lambda value nvars: number nonzero coefficients (, including intercept) value lambda nonzero: column names indicating nonzero coefficients model specified value lambda constant_features: character vector names columns design matrix whose values constant whole sample (e.g., monomorphic SNPs genetics context)","code":""},{"path":"/reference/summary.plmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A summary method for the plmm objects — summary.plmm","text":"","code":"fit <- cv.plmm(X = admix$X, y = admix$y, K = relatedness_mat(admix$X)) summary(fit$fit, idx = 97) #> MCP-penalized regression model with n=197, p=101 at lambda=0.00053 #> ------------------------------------------------- #> The model converged  #> ------------------------------------------------- #> # of non-zero coefficients:  98  #> ------------------------------------------------- summary(fit, lambda = fit$lambda.min) #> MCP-penalized model with n=197 and p=100 #> At minimum cross-validation error (lambda=0.4279): #> ------------------------------------------------- #>   Nonzero coefficients: 0 #>   Cross-validation error (deviance): 1.97 #>   Scale estimate (sigma): 1.403"},{"path":"/reference/svd_X.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to implement singular value decomposition for a PLMM or LMM\nThis is an internal function to plmm_prep() — svd_X","title":"A function to implement singular value decomposition for a PLMM or LMM\nThis is an internal function to plmm_prep() — svd_X","text":"function implement singular value decomposition PLMM LMM internal function plmm_prep()","code":""},{"path":"/reference/svd_X.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to implement singular value decomposition for a PLMM or LMM\nThis is an internal function to plmm_prep() — svd_X","text":"","code":"svd_X(X, k, trunc, trace)"},{"path":"/reference/svd_X.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to implement singular value decomposition for a PLMM or LMM\nThis is an internal function to plmm_prep() — svd_X","text":"X standardized design matrix k Optional integer argument indicating number singular values use truncated SVD. See details. trunc Logical: truncated SVD used? trace Logical: messages printed console?","code":""},{"path":"/reference/svd_X.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A function to implement singular value decomposition for a PLMM or LMM\nThis is an internal function to plmm_prep() — svd_X","text":"kind SVD implemented depend combination arguments supplied. (1) trunc = FALSE use base::svd(K) (2) trunc = TRUE use RSpectra::svds(K, k = k)","code":""},{"path":"/reference/test_eta_estimation.html","id":null,"dir":"Reference","previous_headings":"","what":"a function to write tests of estimate_eta — test_eta_estimation","title":"a function to write tests of estimate_eta — test_eta_estimation","text":"function write tests estimate_eta","code":""},{"path":"/reference/test_eta_estimation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a function to write tests of estimate_eta — test_eta_estimation","text":"","code":"test_eta_estimation(sig_s, sig_eps, K, ...)"},{"path":"/reference/test_eta_estimation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a function to write tests of estimate_eta — test_eta_estimation","text":"sig_s Variance attributable structure sig_eps Variance random error K Matrix use relatedness matrix. ... Additional args pass estimate_eta()","code":""},{"path":"/reference/toy_corr_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to generate correlated data for testing purposes — toy_corr_dat","title":"A function to generate correlated data for testing purposes — toy_corr_dat","text":"function generate correlated data testing purposes","code":""},{"path":"/reference/toy_corr_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to generate correlated data for testing purposes — toy_corr_dat","text":"","code":"toy_corr_dat(n = 100, p = 256, s = 4, gamma = 6, beta = 2, B = 20)"},{"path":"/reference/toy_corr_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to generate correlated data for testing purposes — toy_corr_dat","text":"n Number observations p Number features s Number significant (truly associated) features gamma Magnitude greatest group mean confounding beta Magnitude true coefficient values correpsonding sigificant features B Number groups (e.g., batches, families)","code":""},{"path":"/reference/toy_corr_dat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to generate correlated data for testing purposes — toy_corr_dat","text":"list 'toy' data","code":""},{"path":"/reference/untransform.html","id":null,"dir":"Reference","previous_headings":"","what":"Untransform coefficient values back to the original scale — untransform","title":"Untransform coefficient values back to the original scale — untransform","text":"function unwinds initial standardization data obtain coefficient values original scale. called plmm_format().","code":""},{"path":"/reference/untransform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Untransform coefficient values back to the original scale — untransform","text":"","code":"untransform(untransformed_b1, ns, p, std_X_details)"},{"path":"/reference/untransform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Untransform coefficient values back to the original scale — untransform","text":"untransformed_b1 estimated coefficients standardized scale ns indices non-singular columns ORIGINAL design matrix p number columns original design matrix (without intercept) std_X_details list 3 elements describing standardized design matrix rotation; elements 'scale', 'center', 'nonsingular'","code":""},{"path":"/reference/v_hat.html","id":null,"dir":"Reference","previous_headings":"","what":"a function to create the estimated variance matrix from a PLMM fit — v_hat","title":"a function to create the estimated variance matrix from a PLMM fit — v_hat","text":"function create estimated variance matrix PLMM fit","code":""},{"path":"/reference/v_hat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a function to create the estimated variance matrix from a PLMM fit — v_hat","text":"","code":"v_hat(fit, K = NULL)"},{"path":"/reference/v_hat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a function to create the estimated variance matrix from a PLMM fit — v_hat","text":"fit object returned plmm() K optional matrix list returned choose_K()","code":""},{"path":"/reference/v_hat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"a function to create the estimated variance matrix from a PLMM fit — v_hat","text":"Vhat, matrix representing estimated variance","code":""},{"path":"/reference/varp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the population variance — varp","title":"Calculate the population variance — varp","text":"function allows calculate population variance; assume sample population.","code":""},{"path":"/reference/varp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the population variance — varp","text":"","code":"varp(x)"},{"path":"/reference/varp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the population variance — varp","text":"x numeric vector","code":""},{"path":"/reference/varp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the population variance — varp","text":"","code":"if (FALSE) { v <- rnorm(5) varp(v) }"},{"path":"/news/index.html","id":"plmmr-221","dir":"Changelog","previous_headings":"","what":"plmmr 2.2.1","title":"plmmr 2.2.1","text":"Initial CRAN submission.","code":""},{"path":"/news/index.html","id":"major-changes-2-2-1","dir":"Changelog","previous_headings":"","what":"Major changes","title":"plmmr 2.2.1","text":"Changed package name plmmr - note plmm(), cv.plmm(), functions starting plmm_ changed names.","code":""}]
